['Outer', 'Inner', 'Reduction', 'VarDecl', 'refExpr', 'intLiteral', 'floatLiteral', 'mem_to', 'mem_from', 'add_sub_int', 'add_sub_double', 'mul_int', 'mul_double', 'div_int', 'div_double', 'assign_int', 'assign_double', 'log_Outer', 'log_Inner', 'log_VarDecl', 'log_refExpr', 'log_intLiteral', 'log_floatLiteral', 'log_mem_to', 'log_mem_from', 'log_add_sub_int', 'log_add_sub_double', 'log_mul_int', 'log_mul_double', 'log_div_int', 'log_div_double', 'log_assign_int', 'log_assign_double', 'runtimes']
2733
34
<class 'numpy.dtype'> float64
2733
train batches:  124  validate samples: 218  test samples: 546
Epoch [0/75], Batch loss: 29.662
Epoch: 0 RMSE:  37.02940601162745  MAPE: 3.6370415835595113  L2+L1 loss: 23.755
Epoch [1/75], Batch loss: 22.624
Epoch: 1 RMSE:  31.349583971250745  MAPE: 1.6136283069568922  L2+L1 loss: 16.037
Epoch [2/75], Batch loss: 22.508
Epoch: 2 RMSE:  31.31675413327979  MAPE: 1.6581393067547678  L2+L1 loss: 16.104
Epoch [3/75], Batch loss: 22.65
Epoch: 3 RMSE:  41.26008206635335  MAPE: 0.8516515206101551  L2+L1 loss: 22.687
Epoch [4/75], Batch loss: 22.112
Epoch: 4 RMSE:  34.127508131838766  MAPE: 0.6813257434628064  L2+L1 loss: 15.57
Epoch [5/75], Batch loss: 23.435
Epoch: 5 RMSE:  32.134611591025504  MAPE: 1.111797594143421  L2+L1 loss: 15.135
Epoch [6/75], Batch loss: 22.351
Epoch: 6 RMSE:  31.601762465768427  MAPE: 1.3771911014547322  L2+L1 loss: 15.609
Epoch [7/75], Batch loss: 22.795
Epoch: 7 RMSE:  31.520623431379295  MAPE: 1.4437363113295376  L2+L1 loss: 15.754
Epoch [8/75], Batch loss: 22.642
Epoch: 8 RMSE:  31.489797567035932  MAPE: 1.4747418110907686  L2+L1 loss: 15.828
Epoch [9/75], Batch loss: 83.23
Epoch: 9 RMSE:  31.59218838583528  MAPE: 1.3842734328317572  L2+L1 loss: 15.625
Epoch [10/75], Batch loss: 27.493
Epoch: 10 RMSE:  31.61305053546183  MAPE: 1.3690412092156683  L2+L1 loss: 15.592
Epoch [11/75], Batch loss: 22.295
Epoch: 11 RMSE:  31.586791910051172  MAPE: 1.3883386181182606  L2+L1 loss: 15.633
Epoch [12/75], Batch loss: 22.338
Epoch: 12 RMSE:  31.557501133607822  MAPE: 1.4114369438031968  L2+L1 loss: 15.683
Epoch [13/75], Batch loss: 22.68
Epoch: 13 RMSE:  31.522968997808967  MAPE: 1.4415421622587596  L2+L1 loss: 15.748
Epoch [14/75], Batch loss: 99.102
Epoch: 14 RMSE:  31.583126099962957  MAPE: 1.388027210068723  L2+L1 loss: 15.621
Epoch [15/75], Batch loss: 22.168
Epoch: 15 RMSE:  31.568678084704235  MAPE: 1.4023839861737595  L2+L1 loss: 15.663
Epoch [16/75], Batch loss: 22.622
Epoch: 16 RMSE:  31.54784582962277  MAPE: 1.4194837422851438  L2+L1 loss: 15.699
Epoch [17/75], Batch loss: 52.636
Epoch: 17 RMSE:  31.420721247494914  MAPE: 1.4289030402188287  L2+L1 loss: 15.122
Epoch [18/75], Batch loss: 22.59
Epoch: 18 RMSE:  31.446761953709785  MAPE: 1.5285470569278659  L2+L1 loss: 15.975
Epoch [19/75], Batch loss: 22.277
Epoch: 19 RMSE:  31.450361191243417  MAPE: 1.52334741436695  L2+L1 loss: 15.96
Epoch [20/75], Batch loss: 22.34
Epoch: 20 RMSE:  31.460825641082547  MAPE: 1.5090473442877184  L2+L1 loss: 15.917
Epoch [21/75], Batch loss: 22.34
Epoch: 21 RMSE:  31.471526935081  MAPE: 1.4955980715968684  L2+L1 loss: 15.88
Epoch [22/75], Batch loss: 22.189
Epoch: 22 RMSE:  31.474050515062675  MAPE: 1.4925760877614354  L2+L1 loss: 15.872
Epoch [23/75], Batch loss: 22.395
Epoch: 23 RMSE:  31.493218783015624  MAPE: 1.4710587587825334  L2+L1 loss: 15.818
Epoch [24/75], Batch loss: 22.393
Epoch: 24 RMSE:  31.498353992208944  MAPE: 1.465642398644744  L2+L1 loss: 15.804
Epoch [25/75], Batch loss: 22.601
Epoch: 25 RMSE:  31.481765967485565  MAPE: 1.4836424383521911  L2+L1 loss: 15.85
Epoch [26/75], Batch loss: 22.623
Epoch: 26 RMSE:  31.47019252805415  MAPE: 1.497214793973675  L2+L1 loss: 15.884
Epoch [27/75], Batch loss: 22.27
Epoch: 27 RMSE:  31.47377861907542  MAPE: 1.492899498577477  L2+L1 loss: 15.873
Epoch [28/75], Batch loss: 22.145
Epoch: 28 RMSE:  31.493299767395683  MAPE: 1.4709723160964494  L2+L1 loss: 15.818
Epoch [29/75], Batch loss: 24.345
Epoch: 29 RMSE:  171.81450175333896  MAPE: 5.452196239153768  L2+L1 loss: 85.369
Epoch [30/75], Batch loss: 25.153
Epoch: 30 RMSE:  30.05222110721182  MAPE: 0.2281582633912497  L2+L1 loss: 9.754
Epoch [31/75], Batch loss: 18.342
Epoch: 31 RMSE:  29.908279175331405  MAPE: 0.19081712828527062  L2+L1 loss: 9.419
Epoch [32/75], Batch loss: 18.524
Epoch: 32 RMSE:  29.73156578272792  MAPE: 0.20706442586825932  L2+L1 loss: 9.238
Epoch [33/75], Batch loss: 17.719
Epoch: 33 RMSE:  29.57353978440078  MAPE: 0.18787675075043556  L2+L1 loss: 9.171
Epoch [34/75], Batch loss: 17.398
Epoch: 34 RMSE:  29.397790852867107  MAPE: 0.1904390915684889  L2+L1 loss: 8.881
Epoch [35/75], Batch loss: 17.286
Epoch: 35 RMSE:  29.2537636980314  MAPE: 0.23596237200775413  L2+L1 loss: 9.036
Epoch [36/75], Batch loss: 17.78
Epoch: 36 RMSE:  29.05620900449656  MAPE: 0.1521677091930134  L2+L1 loss: 8.466
Epoch [37/75], Batch loss: 16.378
Epoch: 37 RMSE:  28.728756951468938  MAPE: 0.9671133736772269  L2+L1 loss: 16.567
Epoch [38/75], Batch loss: 6.649
Epoch: 38 RMSE:  3.9442723581309274  MAPE: 0.10135809319394107  L2+L1 loss: 2.252
Epoch [39/75], Batch loss: 5.57
Epoch: 39 RMSE:  8.25219551323328  MAPE: 0.21112015354637004  L2+L1 loss: 3.375
Epoch [40/75], Batch loss: 5.304
Epoch: 40 RMSE:  3.963648105714318  MAPE: 0.0996078096411832  L2+L1 loss: 1.971
Epoch [41/75], Batch loss: 3.15
Epoch: 41 RMSE:  4.61909117544165  MAPE: 0.10057538468067184  L2+L1 loss: 2.186
Epoch [42/75], Batch loss: 3.795
Epoch: 42 RMSE:  2.8139964283593613  MAPE: 0.06192588454433129  L2+L1 loss: 1.787
Epoch [43/75], Batch loss: 4.866
Epoch: 43 RMSE:  2.554577855265751  MAPE: 0.09193333745984276  L2+L1 loss: 1.732
Epoch [44/75], Batch loss: 6.915
Epoch: 44 RMSE:  4.142336118637866  MAPE: 0.09649721842347661  L2+L1 loss: 2.548
Epoch [45/75], Batch loss: 2.547
Epoch: 45 RMSE:  4.059212282558002  MAPE: 0.09942409370090335  L2+L1 loss: 2.033
Epoch [46/75], Batch loss: 3.07
Epoch: 46 RMSE:  7.102242772639455  MAPE: 0.11817403067849797  L2+L1 loss: 3.621
Epoch [47/75], Batch loss: 4.136
Epoch: 47 RMSE:  2.146036417022886  MAPE: 0.0884104262363225  L2+L1 loss: 1.575
Epoch [48/75], Batch loss: 2.799
Epoch: 48 RMSE:  1.8186115461115542  MAPE: 0.09347484157855648  L2+L1 loss: 1.651
Epoch [49/75], Batch loss: 3.18
Epoch: 49 RMSE:  3.482017055619493  MAPE: 0.09927141258154663  L2+L1 loss: 2.355
Epoch [50/75], Batch loss: 2.303
Epoch: 50 RMSE:  10.785511571497159  MAPE: 0.08620255843089189  L2+L1 loss: 3.644
Epoch [51/75], Batch loss: 6.231
Epoch: 51 RMSE:  2.7282225609779607  MAPE: 0.06999523056453956  L2+L1 loss: 1.864
Epoch [52/75], Batch loss: 3.968
Epoch: 52 RMSE:  7.706922836811922  MAPE: 0.1253196642466469  L2+L1 loss: 3.337
Epoch [53/75], Batch loss: 8.421
Epoch: 53 RMSE:  2.3073417411588077  MAPE: 0.10249705336070858  L2+L1 loss: 1.916
Epoch [54/75], Batch loss: 2.486
Epoch: 54 RMSE:  1.831083076385996  MAPE: 0.09717047210567405  L2+L1 loss: 1.642
Epoch [55/75], Batch loss: 1.926
Epoch: 55 RMSE:  1.725718440725614  MAPE: 0.06491978818865948  L2+L1 loss: 1.468
Epoch [56/75], Batch loss: 3.35
Epoch: 56 RMSE:  2.065612282238766  MAPE: 0.06528304313852222  L2+L1 loss: 1.533
Epoch [57/75], Batch loss: 1.808
Epoch: 57 RMSE:  1.9325103079513721  MAPE: 0.08406048023569482  L2+L1 loss: 1.625
Epoch [58/75], Batch loss: 2.444
Epoch: 58 RMSE:  2.9651004212736827  MAPE: 0.0666993472675511  L2+L1 loss: 1.775
Epoch [59/75], Batch loss: 3.195
Epoch: 59 RMSE:  1.6438962646495283  MAPE: 0.07528865735906946  L2+L1 loss: 1.452
Epoch [60/75], Batch loss: 1.374
Epoch: 60 RMSE:  1.4354708751271503  MAPE: 0.05346648012935315  L2+L1 loss: 1.268
Epoch [61/75], Batch loss: 1.348
Epoch: 61 RMSE:  1.4199770255151252  MAPE: 0.05162037354999315  L2+L1 loss: 1.261
Epoch [62/75], Batch loss: 1.393
Epoch: 62 RMSE:  1.5139613740182332  MAPE: 0.05352727567248992  L2+L1 loss: 1.318
Epoch [63/75], Batch loss: 1.345
Epoch: 63 RMSE:  1.3316295702172805  MAPE: 0.050502764123606686  L2+L1 loss: 1.232
Epoch [64/75], Batch loss: 1.341
Epoch: 64 RMSE:  1.5505505870347764  MAPE: 0.05509796927666783  L2+L1 loss: 1.343
Epoch [65/75], Batch loss: 1.331
Epoch: 65 RMSE:  1.4910617891155908  MAPE: 0.06422765516026298  L2+L1 loss: 1.304
Epoch [66/75], Batch loss: 1.33
Epoch: 66 RMSE:  1.3941391606387028  MAPE: 0.05105432717547343  L2+L1 loss: 1.259
Epoch [67/75], Batch loss: 1.322
Epoch: 67 RMSE:  1.3813046360034495  MAPE: 0.047538762703258935  L2+L1 loss: 1.249
Epoch [68/75], Batch loss: 1.285
Epoch: 68 RMSE:  1.3717224773361312  MAPE: 0.05301989150326721  L2+L1 loss: 1.238
Epoch [69/75], Batch loss: 1.312
Epoch: 69 RMSE:  1.3192021705104717  MAPE: 0.04693903045450735  L2+L1 loss: 1.213
Epoch [70/75], Batch loss: 1.3
Epoch: 70 RMSE:  1.3408725044591976  MAPE: 0.04997048645443572  L2+L1 loss: 1.215
Epoch [71/75], Batch loss: 1.251
Epoch: 71 RMSE:  1.2966283695652876  MAPE: 0.04761751523284037  L2+L1 loss: 1.194
Epoch [72/75], Batch loss: 1.264
Epoch: 72 RMSE:  1.4182951090120106  MAPE: 0.07790623209798314  L2+L1 loss: 1.313
Epoch [73/75], Batch loss: 1.28
Epoch: 73 RMSE:  1.322364463074184  MAPE: 0.04870158745814158  L2+L1 loss: 1.21
Epoch [74/75], Batch loss: 1.261
Epoch: 74 RMSE:  1.3110201792935494  MAPE: 0.04718222020879918  L2+L1 loss: 1.181


Evaluating Model.......
Best Model - RMSE: inf  MAPE: inf  L2+L1- inf
predicted_runtime, ground_truth
136.74777 , 137.6545
4.8043156 , 5.158
13.033726 , 11.9492
20.16119 , 19.7736
5.175123 , 5.0687
1.5808735 , 1.5037
1.749466 , 1.5589
11.219086 , 10.7525
9.678392 , 9.2197
5.3821983 , 5.3952
22.5406 , 22.3798
25.822575 , 24.7965
8.990935 , 8.5515
0.8228588 , 1.1279
7.4262943 , 7.2651
1.6580315 , 1.9483
5.16436 , 5.7023
13.3661 , 12.7356
6.5811863 , 6.338
87.19743 , 85.1442
19.732174 , 21.3647
1.612381 , 1.5966
20.150145 , 22.6874
30.531425 , 28.7135
21.285498 , 23.7112
5.3510666 , 5.3123
112.829506 , 112.9185
49.97599 , 48.9162
31.194435 , 29.2488
17.603247 , 19.8001
4.060446 , 3.9351
30.278572 , 28.891
131.5358 , 129.1622
6.538618 , 6.5287
8.540875 , 8.4968
11.225722 , 11.0323
11.809482 , 12.7913
112.5121 , 112.5672
154.26164 , 151.7387
1.9443398 , 1.6617
9.363305 , 9.9667
7.3046 , 7.1291
5.756073 , 5.6218
7.4032993 , 7.2552
8.434648 , 9.202
10.896934 , 11.5556
15.326725 , 15.3059
7.882757 , 8.3933
9.087938 , 8.8335
60.23974 , 67.6117
5.811697 , 5.8854
9.908753 , 9.575
8.567387 , 9.0448
8.137402 , 7.7921
27.219837 , 29.691
9.222609 , 8.9075
23.941896 , 26.5459
5.788803 , 6.0943
1.0299492 , 1.066
17.167643 , 16.504
5.594652 , 5.9118
8.064348 , 7.5085
1.5972996 , 1.4952
13.557651 , 14.1372
7.234379 , 6.993
24.662254 , 23.9209
25.784706 , 24.5494
9.957925 , 9.5344
109.179375 , 106.9881
8.076717 , 8.6174
7.0654182 , 6.7205
23.066078 , 26.002
18.13 , 17.2957
43.048035 , 38.9111
1.355175 , 1.2177
5.2494926 , 5.0972
20.705233 , 21.8898
25.58878 , 24.8778
9.482048 , 10.105
23.297861 , 25.0477
8.038258 , 7.8649
12.543123 , 13.2701
25.293291 , 24.8262
11.374764 , 11.8825
11.866907 , 11.3393
28.780224 , 29.1971
22.05014 , 23.4293
21.900732 , 22.5543
30.109175 , 27.3309
20.543505 , 19.409
5.309952 , 5.1562
6.421234 , 6.4547
8.50015 , 8.8908
13.293068 , 15.4025
6.488323 , 6.9763
20.586355 , 19.9587
6.151127 , 6.0667
1.6363239 , 1.5135
7.26054 , 7.7369
23.216362 , 23.9711
9.602024 , 9.1348
6.2994328 , 6.3014
10.839412 , 10.3898
62.7069 , 57.3748
5.7898693 , 6.1005
21.165024 , 21.937
11.830346 , 10.9715
11.933185 , 11.3761
6.6754932 , 6.6849
17.037407 , 17.2126
0.9886074 , 1.2184
31.509438 , 29.8344
25.474787 , 24.8233
4.7407455 , 5.0246
21.799612 , 23.2352
8.5518 , 8.1415
6.623127 , 7.0575
7.5496254 , 7.8925
18.099195 , 18.2755
7.424595 , 7.0904
39.50176 , 39.9636
1.7294655 , 1.5991
28.059412 , 31.3872
5.796652 , 5.4944
20.05983 , 18.7926
41.298656 , 36.3443
25.793968 , 24.2818
1.0329247 , 1.1706
19.470213 , 18.6419
14.833051 , 14.3968
14.987529 , 13.8541
7.5523796 , 7.9394
6.39571 , 7.0737
11.207773 , 10.3469
7.0210133 , 7.3541
47.014534 , 44.9839
55.480602 , 58.8537
47.478928 , 51.6431
10.958377 , 11.5324
7.391514 , 7.7541
7.468445 , 7.3545
5.160265 , 5.2468
7.9521313 , 8.3835
31.012058 , 30.5763
5.363125 , 5.6767
4.929474 , 5.3792
106.178085 , 105.0823
7.3680534 , 7.2643
19.38569 , 19.8812
15.60492 , 15.1414
20.524464 , 19.338
0.9785347 , 1.1769
17.373661 , 16.6122
12.86287 , 13.449
9.021724 , 9.4493
5.721241 , 5.4999
26.914371 , 26.9464
1.3359795 , 1.0962
96.01783 , 94.581
22.388197 , 21.6738
0.95186424 , 1.1501
32.57926 , 35.6393
1.8479462 , 1.8846
28.75272 , 28.5942
7.721636 , 7.4159
28.795073 , 26.7537
30.207584 , 32.0231
24.985807 , 26.1311
7.407913 , 7.994
8.9751215 , 8.5862
1.1094227 , 1.1622
20.604076 , 20.3385
15.983705 , 15.3712
16.777832 , 16.9755
7.1575375 , 7.2037
12.763683 , 12.2117
23.09025 , 22.7851
43.095825 , 44.3655
23.43607 , 25.0438
9.293976 , 9.9326
23.58363 , 23.1802
33.04505 , 36.4621
23.57084 , 22.48
21.02382 , 20.4797
10.225396 , 10.7467
11.787577 , 12.4269
19.579063 , 21.9377
11.896517 , 12.4516
7.4037457 , 7.1314
27.776815 , 30.9978
0.8518963 , 1.152
27.249577 , 25.8231
24.41626 , 23.4932
10.478128 , 9.7026
20.861427 , 21.1576
9.610987 , 10.2132
28.436424 , 26.9587
24.976944 , 27.6834
19.112267 , 19.4135
19.787022 , 19.8401
33.41095 , 34.2522
2.3371277 , 1.9493
6.2897377 , 6.7306
16.418726 , 14.7707
13.08736 , 12.6773
5.129513 , 4.9704
6.9697914 , 6.8729
22.015453 , 20.9887
9.52775 , 9.1435
11.960286 , 11.0771
2.3832264 , 2.5058
8.342003 , 9.0334
1.4252644 , 1.1686
18.090782 , 17.5595
21.428602 , 19.9483
6.7880497 , 7.1993
4.888788 , 4.6728
7.5278015 , 7.3011
11.571778 , 12.9017
7.831604 , 7.5354
9.43217 , 8.8767
43.83947 , 38.552
9.503442 , 9.0437
7.65942 , 8.2739
27.723284 , 26.8501
5.0283413 , 4.6506
34.16197 , 30.9875
10.693026 , 11.243
4.921076 , 5.2326
4.9077377 , 4.8414
5.9462833 , 5.738
25.986715 , 24.8857
12.690345 , 12.2378
1.1566963 , 1.3716
8.093176 , 7.863
6.262808 , 6.6111
11.85325 , 11.1238
47.30127 , 46.8585
8.246895 , 8.0108
9.758673 , 9.635
19.855804 , 17.7125
22.241728 , 21.1541
21.950415 , 23.4217
48.40316 , 48.1756
5.572777 , 6.0533
65.142944 , 65.4885
0.765852 , 1.0469
16.932034 , 17.1899
7.4552193 , 7.8505
10.4061775 , 11.1638
8.803356 , 9.2202
20.81519 , 20.0594
4.603325 , 4.507
2.2287407 , 2.0877
25.5991 , 24.4912
7.493616 , 7.8943
5.2039204 , 5.1382
42.380165 , 42.2289
19.332443 , 21.1538
1.7260494 , 1.6348
8.077892 , 8.6487
1.5639801 , 1.7502
14.549394 , 14.7895
26.361656 , 26.9633
15.428474 , 16.6194
14.192661 , 14.8068
8.91544 , 8.4724
52.69633 , 57.6766
8.661903 , 9.2154
18.729748 , 17.5241
4.241602 , 4.1246
26.762796 , 25.6484
12.133795 , 11.5346
6.97402 , 7.1081
30.615475 , 29.2077
14.008398 , 13.5579
9.246106 , 9.2701
28.022478 , 25.7785
36.975254 , 32.9861
4.720825 , 4.5162
6.074604 , 5.9266
20.045937 , 19.084
31.78152 , 29.7914
8.649231 , 8.3683
39.001194 , 38.8459
19.597816 , 21.7409
11.149843 , 11.6089
7.0799446 , 7.6784
18.483576 , 18.4591
29.055353 , 26.9054
31.28105 , 30.6582
208.21494 , 212.6642
28.021229 , 30.8901
8.503612 , 7.9888
18.393976 , 17.8104
30.18767 , 28.6759
4.8533726 , 4.8592
20.524752 , 19.5506
1.3481693 , 1.3262
30.744892 , 32.5337
49.476173 , 51.174
8.465182 , 8.059
6.1346703 , 6.047
4.5355873 , 4.3147
24.404612 , 23.3821
15.731501 , 16.217
6.5225105 , 6.8508
4.903116 , 4.7991
26.911985 , 25.5127
1.0567131 , 1.3508
28.83255 , 30.1115
30.45176 , 28.9184
38.030983 , 36.8031
9.857229 , 9.3918
5.9518604 , 5.8788
10.216488 , 9.6963
15.09531 , 15.7636
5.975168 , 5.5767
29.851149 , 26.5433
13.460546 , 13.0947
29.455967 , 27.4131
4.965664 , 5.015
35.92964 , 35.1671
8.014763 , 8.5479
27.497467 , 25.8148
6.8961105 , 6.6063
11.202599 , 10.5438
16.907192 , 16.7363
30.027822 , 28.2643
7.5462837 , 7.91
12.400676 , 13.2088
7.8896847 , 7.9021
5.6964073 , 6.1438
45.319 , 44.5832
29.39874 , 32.312
11.782506 , 11.0363
10.924899 , 10.287
7.6133213 , 7.268
6.2982044 , 6.6165
8.496887 , 9.0972
35.99117 , 37.5664
29.405369 , 28.7032
8.173124 , 8.5788
27.336382 , 28.5326
5.4901943 , 6.0133
7.637352 , 7.2382
5.302309 , 5.2487
7.0963173 , 6.8477
5.0459957 , 5.0378
0.7298622 , 1.0533
10.015697 , 10.5723
0.97369385 , 1.174
7.561613 , 8.5534
9.426522 , 9.1562
0.92840576 , 1.0243
4.906027 , 4.6835
24.41626 , 27.038
6.4022865 , 6.3322
39.2606 , 42.9192
31.827665 , 34.7377
18.30532 , 19.2113
26.577433 , 27.7562
12.168048 , 12.8144
57.587708 , 56.0988
6.0408325 , 6.3458
23.535374 , 23.1345
2.1334915 , 2.135
12.170627 , 11.6448
5.387556 , 5.3057
21.522236 , 23.0522
40.61573 , 42.8951
10.527826 , 10.1257
14.315658 , 14.4882
5.9439106 , 6.3073
0.7690468 , 1.0054
8.514648 , 8.5077
7.7621593 , 8.1281
6.272558 , 6.6805
23.303122 , 24.8597
22.641703 , 21.9858
7.8481674 , 7.4943
49.487385 , 48.0414
8.901442 , 9.3289
1.6997833 , 1.8568
13.630295 , 13.039
9.525048 , 10.0052
9.274767 , 10.1274
25.936968 , 24.7676
8.859777 , 9.1175
4.5673294 , 4.4916
1.2286797 , 1.1964
10.5041685 , 10.9884
23.489334 , 24.0753
7.945448 , 7.4711
13.555445 , 12.2911
4.3384514 , 4.1431
31.76131 , 29.7459
23.467333 , 26.9055
31.973364 , 34.9449
6.0792236 , 6.5891
27.514399 , 25.8079
6.948723 , 7.4403
5.2810974 , 5.6451
4.0902767 , 4.3839
31.89603 , 30.6962
6.186653 , 6.0012
6.979204 , 7.258
41.684402 , 44.7931
4.323244 , 4.1258
6.5383644 , 7.0406
2.0472775 , 2.0459
6.719738 , 6.7173
41.289074 , 43.9626
20.26254 , 22.5925
22.287462 , 23.006
7.055231 , 6.9189
18.677088 , 18.2954
9.461938 , 9.9524
22.623468 , 23.1179
1.4402599 , 1.436
8.260378 , 7.9511
49.51013 , 43.853
8.185488 , 8.3098
8.810972 , 8.0405
29.88447 , 30.9425
29.618963 , 27.9781
22.223118 , 21.782
144.9982 , 145.9228
8.617645 , 9.0091
15.587217 , 14.6678
6.88616 , 6.6567
44.770164 , 44.767
44.59459 , 42.1206
8.118607 , 7.9249
6.254223 , 6.7903
17.797096 , 19.111
149.30957 , 150.5184
5.1262856 , 5.4532
45.72805 , 49.9474
22.04331 , 24.6451
67.69069 , 75.8477
15.468019 , 15.1967
50.726273 , 47.2121
20.465645 , 19.2398
6.2980328 , 6.6063
7.7296295 , 7.3117
2.0784206 , 2.2219
51.852577 , 57.1384
9.1624565 , 9.639
6.082651 , 5.8848
3.7206001 , 4.1716
6.0584545 , 6.3786
24.727764 , 24.0739
7.7918396 , 7.4145
1.6232204 , 1.4629
9.873448 , 10.512
4.523405 , 4.4981
37.89449 , 39.7144
27.8824 , 30.1902
7.7202396 , 7.3311
7.2085857 , 7.0188
1.3085022 , 1.4283
12.661391 , 12.3629
18.351599 , 18.2391
25.827606 , 29.0599
6.801338 , 6.6859
7.055826 , 6.8678
8.668678 , 9.2528
25.956758 , 26.0681
4.4292107 , 4.2777
6.674076 , 7.0445
16.709476 , 16.4065
6.227335 , 5.7696
9.851465 , 9.4514
38.821297 , 35.9352
23.022358 , 22.2235
8.257868 , 8.6685
24.41626 , 23.7019
110.04072 , 107.1644
12.351011 , 12.513
33.27542 , 32.4659
19.928604 , 21.7521
22.160612 , 22.3974
218.22516 , 214.9769
16.792576 , 17.5409
5.0590935 , 5.0059
1.2941933 , 1.3092
29.851486 , 30.718
14.72984 , 16.0225
6.128975 , 6.278
7.396534 , 7.7113
16.548172 , 16.9392
2.8594666 , 2.6348
12.05619 , 12.9114
9.46224 , 10.0347
92.09797 , 92.2644
2.7051659 , 2.2031
13.852095 , 14.6567
6.904318 , 6.6813
28.270796 , 26.6828
1.9532738 , 1.8709
5.620865 , 5.4406
6.0308743 , 6.3534
5.329941 , 5.9045
34.510384 , 37.0987
24.156406 , 22.2277
6.7778206 , 7.0984
22.16474 , 21.0818
6.6349487 , 6.9933
6.800667 , 6.5723
8.657448 , 8.0561
7.975235 , 8.2693
89.75693 , 87.5367
42.601517 , 42.5586
12.348588 , 12.307
31.060041 , 32.5123
26.331535 , 26.7897
7.524172 , 7.2698
18.91383 , 17.8406
5.3565845 , 5.2107
12.861654 , 13.6417
1.7890148 , 1.9445
5.139597 , 5.426
7.90518 , 8.2962
20.038822 , 19.4759
52.739616 , 58.6507
1.8407593 , 2.0558
38.988422 , 37.5075
22.890415 , 25.2426
22.0349 , 23.4857
4.787815 , 4.8142
23.744246 , 23.0704
11.251947 , 10.7932
18.093233 , 17.8717
13.448517 , 13.0737
15.398153 , 16.5936
11.847902 , 11.3083
8.686427 , 8.4191
1.19874 , 1.2538
5.8670216 , 5.6447
4.4110317 , 4.3127
2.0955029 , 2.0457
30.632347 , 28.9484
4.948391 , 4.8095
10.719735 , 10.3687
15.608125 , 16.6096
RMSE:  1.3681076471760811  MAPE: 0.053249025270175714
5: ground truth total-  71  predicted total -  71
100: ground truth total-  463  predicted total -  463
 more 100: ground truth total -  12  predicted total -  12
