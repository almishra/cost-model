['Outer', 'Inner', 'Reduction', 'VarDecl', 'refExpr', 'intLiteral', 'floatLiteral', 'mem_to', 'mem_from', 'add_sub_int', 'add_sub_double', 'mul_int', 'mul_double', 'div_int', 'div_double', 'assign_int', 'assign_double', 'log_Outer', 'log_Inner', 'log_VarDecl', 'log_refExpr', 'log_intLiteral', 'log_floatLiteral', 'log_mem_to', 'log_mem_from', 'log_add_sub_int', 'log_add_sub_double', 'log_mul_int', 'log_mul_double', 'log_div_int', 'log_div_double', 'log_assign_int', 'log_assign_double', 'runtimes']
2682
34
<class 'numpy.dtype'> float64
2682
train batches:  121  validate samples: 214  test samples: 536
Epoch [0/75], Batch loss: 47.252
Epoch: 0 RMSE:  22.295871508397155  MAPE: 0.6607100176037078  L2+L1 loss: 11.541
Epoch [1/75], Batch loss: 18.945
Epoch: 1 RMSE:  20.802830246102484  MAPE: 0.6411826700585902  L2+L1 loss: 9.515
Epoch [2/75], Batch loss: 16.989
Epoch: 2 RMSE:  19.820548612868407  MAPE: 1.0970434282958197  L2+L1 loss: 9.864
Epoch [3/75], Batch loss: 16.067
Epoch: 3 RMSE:  19.38651956032249  MAPE: 1.530994218557433  L2+L1 loss: 10.481
Epoch [4/75], Batch loss: 16.53
Epoch: 4 RMSE:  19.339903938300157  MAPE: 1.713030478115398  L2+L1 loss: 10.805
Epoch [5/75], Batch loss: 16.072
Epoch: 5 RMSE:  19.345129747259335  MAPE: 1.8235735875346843  L2+L1 loss: 11.019
Epoch [6/75], Batch loss: 16.293
Epoch: 6 RMSE:  19.35572316815358  MAPE: 1.8720701478562445  L2+L1 loss: 11.115
Epoch [7/75], Batch loss: 16.045
Epoch: 7 RMSE:  19.34657840917166  MAPE: 1.8312594443055772  L2+L1 loss: 11.034
Epoch [8/75], Batch loss: 16.072
Epoch: 8 RMSE:  19.354682286269885  MAPE: 1.8659652629069927  L2+L1 loss: 11.103
Epoch [9/75], Batch loss: 16.192
Epoch: 9 RMSE:  19.357126081931913  MAPE: 1.8747464080433487  L2+L1 loss: 11.121
Epoch [10/75], Batch loss: 16.203
Epoch: 10 RMSE:  19.361058964909112  MAPE: 1.8878328701200993  L2+L1 loss: 11.15
Epoch [11/75], Batch loss: 16.065
Epoch: 11 RMSE:  19.349150063083272  MAPE: 1.8435076251832592  L2+L1 loss: 11.058
Epoch [12/75], Batch loss: 16.164
Epoch: 12 RMSE:  19.358702266358247  MAPE: 1.8801254173829933  L2+L1 loss: 11.133
Epoch [13/75], Batch loss: 15.953
Epoch: 13 RMSE:  19.348853221909685  MAPE: 1.842168778518605  L2+L1 loss: 11.056
Epoch [14/75], Batch loss: 16.142
Epoch: 14 RMSE:  19.353767810272284  MAPE: 1.86251918609273  L2+L1 loss: 11.096
Epoch [15/75], Batch loss: 71.699
Epoch: 15 RMSE:  19.747707820523665  MAPE: 1.8131177980862503  L2+L1 loss: 11.141
Epoch [16/75], Batch loss: 16.328
Epoch: 16 RMSE:  194.17488793383515  MAPE: 46.04572416029718  L2+L1 loss: 137.695
Epoch [17/75], Batch loss: 22.563
Epoch: 17 RMSE:  19.40394373432693  MAPE: 1.7022672447361002  L2+L1 loss: 10.829
Epoch [18/75], Batch loss: 16.109
Epoch: 18 RMSE:  19.38649838337077  MAPE: 1.7562845314812139  L2+L1 loss: 10.923
Epoch [19/75], Batch loss: 16.346
Epoch: 19 RMSE:  19.387601730481506  MAPE: 1.824025914200759  L2+L1 loss: 11.055
Epoch [20/75], Batch loss: 16.373
Epoch: 20 RMSE:  19.409486483356947  MAPE: 1.8234608750716546  L2+L1 loss: 11.066
Epoch [21/75], Batch loss: 19.175
Epoch: 21 RMSE:  19.37835610003036  MAPE: 1.9353985736307877  L2+L1 loss: 11.25
Epoch [22/75], Batch loss: 16.325
Epoch: 22 RMSE:  19.372609006550952  MAPE: 1.8791841873699187  L2+L1 loss: 11.146
Epoch [23/75], Batch loss: 16.769
Epoch: 23 RMSE:  19.369798775934722  MAPE: 1.925905022317713  L2+L1 loss: 11.223
Epoch [24/75], Batch loss: 23.233
Epoch: 24 RMSE:  19.513630793770698  MAPE: 2.1537239760793283  L2+L1 loss: 11.785
Epoch [25/75], Batch loss: 16.17
Epoch: 25 RMSE:  19.422605278092256  MAPE: 2.024269822577968  L2+L1 loss: 11.457
Epoch [26/75], Batch loss: 16.352
Epoch: 26 RMSE:  19.367966103274146  MAPE: 1.9084255545065785  L2+L1 loss: 11.194
Epoch [27/75], Batch loss: 16.205
Epoch: 27 RMSE:  19.356567270763897  MAPE: 1.8727892186708963  L2+L1 loss: 11.117
Epoch [28/75], Batch loss: 15.96
Epoch: 28 RMSE:  19.350483984521407  MAPE: 1.8493219901504443  L2+L1 loss: 11.069
Epoch [29/75], Batch loss: 15.753
Epoch: 29 RMSE:  19.368465914884187  MAPE: 1.909819962996063  L2+L1 loss: 11.197
Epoch [30/75], Batch loss: 16.093
Epoch: 30 RMSE:  19.364974963802933  MAPE: 1.8998298673000316  L2+L1 loss: 11.176
Epoch [31/75], Batch loss: 16.081
Epoch: 31 RMSE:  19.36246323315691  MAPE: 1.8922423411697429  L2+L1 loss: 11.159
Epoch [32/75], Batch loss: 16.047
Epoch: 32 RMSE:  19.36069954578835  MAPE: 1.8866832494801893  L2+L1 loss: 11.147
Epoch [33/75], Batch loss: 16.178
Epoch: 33 RMSE:  19.358638413869105  MAPE: 1.8811855851682764  L2+L1 loss: 11.134
Epoch [34/75], Batch loss: 16.096
Epoch: 34 RMSE:  19.3578643768491  MAPE: 1.877289831025003  L2+L1 loss: 11.127
Epoch [35/75], Batch loss: 16.094
Epoch: 35 RMSE:  19.356051388504742  MAPE: 1.870956661640558  L2+L1 loss: 11.114
Epoch [36/75], Batch loss: 16.236
Epoch: 36 RMSE:  19.356584199285958  MAPE: 1.872848929028349  L2+L1 loss: 11.118
Epoch [37/75], Batch loss: 16.128
Epoch: 37 RMSE:  19.356077374263347  MAPE: 1.8710495775085139  L2+L1 loss: 11.114
Epoch [38/75], Batch loss: 16.143
Epoch: 38 RMSE:  19.354316698325423  MAPE: 1.8645989231564124  L2+L1 loss: 11.1
Epoch [39/75], Batch loss: 16.129
Epoch: 39 RMSE:  19.354814528635732  MAPE: 1.866455900382817  L2+L1 loss: 11.104
Epoch [40/75], Batch loss: 14.303
Epoch: 40 RMSE:  17.88674174401367  MAPE: 0.3895360820514197  L2+L1 loss: 6.482
Epoch [41/75], Batch loss: 13.631
Epoch: 41 RMSE:  17.735640895386627  MAPE: 0.38582946096844606  L2+L1 loss: 6.242
Epoch [42/75], Batch loss: 5.843
Epoch: 42 RMSE:  2.167016387199352  MAPE: 0.2410793169713486  L2+L1 loss: 1.889
Epoch [43/75], Batch loss: 2.536
Epoch: 43 RMSE:  2.0712917926301118  MAPE: 0.14485197900084856  L2+L1 loss: 1.487
Epoch [44/75], Batch loss: 8.965
Epoch: 44 RMSE:  17.37304542659456  MAPE: 0.31331843847673463  L2+L1 loss: 5.29
Epoch [45/75], Batch loss: 12.217
Epoch: 45 RMSE:  17.371267465136476  MAPE: 0.39492695915926934  L2+L1 loss: 5.612
Epoch [46/75], Batch loss: 12.433
Epoch: 46 RMSE:  16.989807190977427  MAPE: 0.22074091254400596  L2+L1 loss: 4.666
Epoch [47/75], Batch loss: 6.053
Epoch: 47 RMSE:  2.901148246850032  MAPE: 0.09468674014425307  L2+L1 loss: 1.477
Epoch [48/75], Batch loss: 5.512
Epoch: 48 RMSE:  16.551476431654056  MAPE: 0.6050675386806563  L2+L1 loss: 6.232
Epoch [49/75], Batch loss: 8.65
Epoch: 49 RMSE:  17.06908172984943  MAPE: 0.15917048101338424  L2+L1 loss: 4.722
Epoch [50/75], Batch loss: 11.967
Epoch: 50 RMSE:  16.899582231594422  MAPE: 0.1605216934350941  L2+L1 loss: 4.536
Epoch [51/75], Batch loss: 11.785
Epoch: 51 RMSE:  16.761240833333254  MAPE: 0.1510778176952585  L2+L1 loss: 4.464
Epoch [52/75], Batch loss: 10.52
Epoch: 52 RMSE:  2.829254479864408  MAPE: 0.20681098458391722  L2+L1 loss: 1.706
Epoch [53/75], Batch loss: 3.621
Epoch: 53 RMSE:  1.757351016481503  MAPE: 0.20504202845270922  L2+L1 loss: 1.645
Epoch [54/75], Batch loss: 2.836
Epoch: 54 RMSE:  3.4006723666431733  MAPE: 0.1979577993673389  L2+L1 loss: 2.469
Epoch [55/75], Batch loss: 3.376
Epoch: 55 RMSE:  1.2109221708575304  MAPE: 0.11930070102263433  L2+L1 loss: 1.231
Epoch [56/75], Batch loss: 3.562
Epoch: 56 RMSE:  17.242232243621146  MAPE: 1.876508240282832  L2+L1 loss: 10.406
Epoch [57/75], Batch loss: 6.371
Epoch: 57 RMSE:  1.9425071001875516  MAPE: 0.18099156104876313  L2+L1 loss: 1.611
Epoch [58/75], Batch loss: 1.734
Epoch: 58 RMSE:  1.7006346790818259  MAPE: 0.10406655558034372  L2+L1 loss: 1.027
Epoch [59/75], Batch loss: 2.228
Epoch: 59 RMSE:  6.325000366670594  MAPE: 0.34765124978931583  L2+L1 loss: 3.577
Epoch [60/75], Batch loss: 2.017
Epoch: 60 RMSE:  0.9424908304108038  MAPE: 0.058230627247053524  L2+L1 loss: 0.838
Epoch [61/75], Batch loss: 1.0
Epoch: 61 RMSE:  0.7692960353575912  MAPE: 0.05410801312227132  L2+L1 loss: 0.762
Epoch [62/75], Batch loss: 0.939
Epoch: 62 RMSE:  1.6687188606730359  MAPE: 0.058600845357804666  L2+L1 loss: 1.034
Epoch [63/75], Batch loss: 0.973
Epoch: 63 RMSE:  0.6713283750125675  MAPE: 0.06446430473671479  L2+L1 loss: 0.764
Epoch [64/75], Batch loss: 0.871
Epoch: 64 RMSE:  0.8204268017581573  MAPE: 0.046887165477785535  L2+L1 loss: 0.75
Epoch [65/75], Batch loss: 1.046
Epoch: 65 RMSE:  1.7139320168892318  MAPE: 0.07367060246357217  L2+L1 loss: 1.053
Epoch [66/75], Batch loss: 0.883
Epoch: 66 RMSE:  0.5266172071306385  MAPE: 0.03841426499548491  L2+L1 loss: 0.622
Epoch [67/75], Batch loss: 0.784
Epoch: 67 RMSE:  0.48982565619254204  MAPE: 0.034960717379568906  L2+L1 loss: 0.582
Epoch [68/75], Batch loss: 0.808
Epoch: 68 RMSE:  0.5804293810282698  MAPE: 0.03921053866020029  L2+L1 loss: 0.623
Epoch [69/75], Batch loss: 1.045
Epoch: 69 RMSE:  0.9065964769992295  MAPE: 0.03694972764517628  L2+L1 loss: 0.751
Epoch [70/75], Batch loss: 0.741
Epoch: 70 RMSE:  0.7165299007374143  MAPE: 0.06075439575035732  L2+L1 loss: 0.744
Epoch [71/75], Batch loss: 0.918
Epoch: 71 RMSE:  0.9780555603255291  MAPE: 0.030965615304632873  L2+L1 loss: 0.678
Epoch [72/75], Batch loss: 0.701
Epoch: 72 RMSE:  0.5992468885450978  MAPE: 0.038999795949269694  L2+L1 loss: 0.577
Epoch [73/75], Batch loss: 0.783
Epoch: 73 RMSE:  0.9833328770014883  MAPE: 0.04181103591281223  L2+L1 loss: 0.753
Epoch [74/75], Batch loss: 0.694
Epoch: 74 RMSE:  0.5894870172471615  MAPE: 0.029805368307960472  L2+L1 loss: 0.536


Evaluating Model.......
Best Model - RMSE: inf  MAPE: inf  L2+L1- inf
predicted_runtime, ground_truth
5.288333 , 4.9024
4.1391907 , 4.1879
20.847998 , 20.4086
1.8843689 , 1.7776
4.55873 , 4.5582
16.693497 , 17.1112
3.1333494 , 3.1444
5.3150063 , 5.4284
4.341954 , 4.33
4.081829 , 4.2349
6.2836637 , 6.2564
4.358617 , 4.5358
25.017649 , 24.4307
13.313179 , 12.8974
4.7131567 , 4.6791
2.9840498 , 4.0708
0.8835144 , 1.0021
1.3189602 , 1.202
7.5381794 , 7.6181
18.466139 , 18.3608
17.411633 , 17.3657
9.115954 , 8.5266
4.538637 , 4.2352
1.4811649 , 1.355
18.539253 , 19.1744
9.382685 , 9.5724
17.22424 , 17.211
93.86926 , 87.5936
4.088643 , 3.9817
25.39568 , 25.4426
8.306267 , 8.4745
18.927986 , 18.7038
4.9932623 , 4.9234
11.117134 , 10.4692
6.447672 , 6.2316
4.834793 , 4.8464
15.788336 , 15.7808
4.9427004 , 4.9974
6.2408752 , 6.2532
4.1744776 , 4.249
11.859862 , 11.8353
39.508514 , 39.7894
10.377305 , 10.1886
1.4316273 , 1.2898
14.665388 , 14.5996
3.8384495 , 3.7441
15.386103 , 15.2262
3.8235168 , 3.73
4.3255024 , 4.3159
14.019943 , 14.0677
4.0416813 , 4.0866
19.28651 , 19.3432
4.0526257 , 4.0146
13.178169 , 13.3847
3.9216099 , 3.811
4.6942673 , 4.6981
4.93198 , 5.5269
3.4357834 , 3.6131
112.64838 , 106.0376
44.18196 , 44.1579
1.5435581 , 1.3516
5.2921314 , 5.3804
3.3704634 , 3.2732
23.716583 , 23.6882
5.008094 , 4.9128
16.194468 , 15.9473
17.1801 , 17.3637
3.5955105 , 3.4817
37.941628 , 37.0336
6.2016697 , 6.3302
28.649582 , 28.9235
17.53171 , 17.8855
13.157816 , 12.9972
15.950896 , 16.0631
4.053751 , 4.0283
14.58108 , 14.631
19.300756 , 18.7421
0.9786835 , 1.028
16.731628 , 17.6003
4.244544 , 4.3284
8.805623 , 8.6762
13.521854 , 13.4273
18.24901 , 18.9935
11.426849 , 11.3459
10.485215 , 10.8373
11.429192 , 10.8714
24.42772 , 23.9746
4.6834 , 4.6905
3.8970861 , 3.9371
4.1993217 , 4.1713
1.7102432 , 1.5208
4.5372477 , 4.5497
6.0889816 , 6.0895
11.116194 , 11.2948
25.159897 , 24.7126
102.819046 , 103.0623
160.68144 , 160.5494
16.884962 , 17.2386
15.350003 , 15.2979
1.367487 , 1.1834
4.7502575 , 4.8551
14.374945 , 14.8113
8.352938 , 8.3748
5.50655 , 5.6193
19.148746 , 19.525
27.076656 , 26.9468
4.095669 , 3.9813
1.0821114 , 1.0154
15.28496 , 15.9801
4.0550528 , 4.0864
37.416428 , 37.8913
18.006798 , 17.9042
9.666264 , 9.5821
5.422242 , 5.609
172.37753 , 172.9229
4.079996 , 3.9496
5.345566 , 5.3789
4.5223913 , 4.4429
3.839693 , 3.8076
4.898589 , 4.9778
3.845008 , 3.7487
3.9711256 , 4.1785
4.186323 , 4.2342
27.10247 , 27.8694
3.477481 , 3.4292
5.8216105 , 6.0492
3.1129694 , 3.174
5.9408884 , 5.807
17.549572 , 17.9614
5.712246 , 5.7097
4.742872 , 4.7997
3.5548973 , 3.628
5.8970146 , 6.2726
24.565079 , 25.0216
4.9558296 , 4.8921
5.122264 , 5.5308
14.845974 , 14.6495
5.872671 , 6.0126
11.281673 , 11.2044
4.4555016 , 4.3823
15.387392 , 15.2212
20.90559 , 20.8913
11.435778 , 11.1734
4.621273 , 4.5306
10.345986 , 10.4654
4.011235 , 4.0329
4.4663954 , 4.3637
6.273432 , 6.2496
16.32283 , 16.6207
4.087001 , 3.9797
13.029131 , 13.1204
1.0274525 , 1.0017
15.25139 , 15.9012
22.743301 , 23.5249
7.087282 , 7.2208
17.066246 , 17.2154
14.867015 , 14.6396
13.82782 , 14.0318
3.805686 , 3.7545
4.2188845 , 4.0777
6.2207193 , 6.3179
4.880705 , 4.9877
21.631771 , 22.0753
3.7872877 , 3.8222
18.407236 , 18.4116
5.316843 , 5.4637
4.271302 , 3.6595
5.0106783 , 4.9135
17.291538 , 17.2073
5.7333937 , 5.8964
21.052423 , 21.1915
12.256428 , 11.5991
3.5563002 , 3.637
4.560074 , 4.6209
9.915439 , 10.3569
15.209803 , 15.2353
4.7049313 , 4.8863
3.8518133 , 3.7639
1.8583546 , 1.8021
14.196413 , 13.3672
90.321014 , 89.1623
4.705597 , 4.7881
17.701157 , 17.998
3.1921806 , 4.0774
21.833212 , 21.6615
3.9090614 , 3.9795
3.98709 , 3.9594
21.698788 , 21.17
12.365924 , 11.531
6.0836563 , 5.646
8.730353 , 8.6894
16.706463 , 16.6702
7.9068174 , 8.034
4.4911976 , 4.593
1.1064816 , 1.2774
3.211134 , 3.1589
28.549166 , 28.1959
4.9301586 , 4.878
4.8444824 , 4.9209
23.14274 , 23.6198
4.86193 , 4.756
4.3870316 , 4.4642
16.068426 , 15.8612
3.5141869 , 3.4384
16.615404 , 16.4815
6.0204268 , 6.0407
1.5169125 , 1.3989
4.738574 , 4.6472
23.791443 , 24.3608
5.3731384 , 5.3826
15.267142 , 15.7643
4.008766 , 3.9039
3.6894217 , 3.5896
2.5039349 , 3.1636
4.560029 , 4.5264
3.6665735 , 3.6816
12.85665 , 13.1425
4.3162365 , 4.2365
4.0810595 , 3.9257
5.105275 , 5.2255
3.9205914 , 3.7652
16.482853 , 17.5086
20.355223 , 20.1963
1.3162422 , 1.1864
4.793145 , 4.8523
20.43519 , 21.5499
19.866863 , 20.1188
13.114003 , 13.2219
96.64546 , 98.1206
5.5200367 , 5.5161
4.0848675 , 4.1286
4.4074526 , 4.3732
13.343495 , 13.2931
3.5823097 , 3.4177
9.183788 , 8.6712
16.124435 , 16.4806
4.600953 , 4.6165
3.8861704 , 3.9296
31.806007 , 32.13
5.1907825 , 5.2156
18.1943 , 18.484
9.479539 , 9.2791
7.8251123 , 7.6488
29.380537 , 29.3167
24.198032 , 23.5808
4.6339035 , 4.6176
18.196285 , 18.2582
30.070059 , 29.5302
12.422518 , 13.2993
9.317682 , 8.7404
14.971961 , 15.1513
15.839647 , 15.5644
5.1157923 , 5.1377
9.179776 , 9.3654
3.6457539 , 3.591
16.512177 , 16.418
19.803577 , 20.0646
38.969246 , 37.5815
89.28801 , 88.9299
14.324632 , 14.8823
3.1458197 , 3.1832
3.560031 , 3.4818
5.807645 , 5.9199
1.5656853 , 1.4065
4.8674145 , 4.9893
26.285133 , 26.2454
23.882977 , 24.3728
16.870363 , 17.6128
3.3159952 , 3.3443
4.4914503 , 4.4386
4.6559124 , 4.8373
18.956924 , 19.1189
18.005037 , 18.0779
4.5203695 , 4.4809
13.522389 , 13.5847
15.541296 , 15.2985
3.365405 , 3.2763
4.809067 , 4.85
8.303719 , 7.7158
5.1998167 , 5.2144
17.75615 , 18.1159
3.7167206 , 3.6437
29.227375 , 27.2531
3.7740946 , 3.6542
17.850882 , 17.9021
5.1593676 , 5.145
4.041771 , 4.1379
14.264311 , 14.0681
4.5867996 , 4.6209
29.224262 , 29.6681
18.860579 , 18.7269
2.307497 , 2.0585
3.5522175 , 3.6303
23.212194 , 23.2686
9.800073 , 9.4835
6.0770874 , 5.6863
5.6108475 , 5.6259
16.180637 , 16.4681
3.6462631 , 3.5862
1.4893723 , 1.3869
5.974641 , 5.7568
5.903455 , 5.9476
3.621091 , 3.5675
17.347546 , 17.7107
9.384166 , 9.7433
5.015726 , 5.0666
8.964443 , 8.8776
3.372467 , 3.4923
1.704237 , 1.6338
6.1129045 , 6.0193
12.306191 , 12.4416
13.61528 , 13.7184
4.7359495 , 4.7497
13.013496 , 12.9123
16.195208 , 15.8678
4.483922 , 4.5094
19.96848 , 20.0289
4.243685 , 4.0821
29.508907 , 29.8689
4.488475 , 4.4699
11.495892 , 11.259
4.304675 , 4.4337
9.641854 , 9.6727
25.323391 , 25.8561
5.3471594 , 5.4138
4.2277517 , 4.3442
4.5558777 , 4.5274
16.066593 , 16.5798
2.0015392 , 1.8036
11.902512 , 11.5969
4.769574 , 4.6432
8.265386 , 8.4447
4.600587 , 4.48
22.152645 , 21.6656
5.84799 , 5.7492
25.586077 , 25.4485
29.907764 , 29.3751
16.54479 , 16.5374
5.133542 , 5.3121
4.8253565 , 4.745
4.2931843 , 4.2392
4.5892715 , 4.4771
16.644958 , 16.5925
5.973077 , 6.0568
4.0948095 , 4.0067
43.11841 , 44.4458
15.25968 , 15.2333
68.898415 , 69.6513
5.7160864 , 5.6528
5.9949684 , 5.9308
15.9248295 , 15.8529
8.654852 , 8.919
5.969326 , 5.7617
5.4619465 , 5.464
13.637644 , 13.8659
5.1778784 , 4.9675
4.3595295 , 4.3069
184.04884 , 185.1429
4.6068535 , 4.6317
12.632128 , 12.6238
3.7873974 , 3.743
3.9223366 , 3.8132
15.212397 , 15.2918
10.894508 , 11.1305
11.791439 , 11.2221
8.237925 , 8.5085
18.984798 , 18.7835
4.643364 , 4.6313
2.0776157 , 1.8314
10.838418 , 10.1218
4.05299 , 4.3099
4.234498 , 4.3239
13.107954 , 12.8327
5.712267 , 5.7637
7.227256 , 7.562
4.092677 , 4.1157
110.98631 , 113.6216
24.427826 , 25.5119
5.712242 , 6.2858
15.438441 , 15.2395
33.062027 , 32.5482
4.4020033 , 4.3287
3.7425919 , 3.7961
5.121423 , 5.0795
15.87907 , 15.8569
17.589481 , 17.3232
17.017736 , 17.1024
12.206801 , 12.716
6.547661 , 6.2536
8.676627 , 9.2515
6.017331 , 5.9195
4.223531 , 4.274
19.243412 , 19.3518
5.767061 , 5.5974
4.913931 , 4.881
10.832712 , 11.5063
4.1991587 , 4.404
15.930102 , 15.9704
1.8694687 , 1.7982
4.7014427 , 4.6104
3.939392 , 3.7605
17.732952 , 17.8868
6.925028 , 5.7453
1.5080643 , 1.354
5.059143 , 5.0554
20.884611 , 21.4805
16.708149 , 17.6653
3.6132708 , 3.6656
6.5494328 , 6.3625
3.5418825 , 3.4253
3.9467545 , 3.8136
6.3916464 , 6.0783
13.5471 , 13.7436
6.0893574 , 6.1625
15.239734 , 15.2916
29.632648 , 28.8733
22.271868 , 23.7843
5.8936844 , 5.8598
5.4743795 , 5.5896
14.039301 , 13.9896
15.06849 , 15.7647
4.710985 , 4.6788
19.793617 , 20.7387
21.092657 , 21.1972
22.47529 , 23.0231
4.8309126 , 4.858
15.589395 , 15.7126
4.590026 , 4.5257
10.144418 , 9.8765
2.370741 , 2.8938
3.9068575 , 3.8787
4.6826677 , 4.6939
34.20272 , 34.2727
21.161877 , 21.1875
5.2325077 , 5.2938
4.0396414 , 3.9111
6.1944275 , 6.1781
16.34383 , 16.6909
2.1781654 , 2.035
4.2992525 , 4.228
17.16927 , 17.3198
3.744689 , 3.7899
4.8495064 , 4.7669
4.007039 , 3.9389
33.104557 , 32.7695
13.429203 , 13.4238
14.335058 , 13.9841
22.313896 , 21.1292
24.858244 , 25.0265
28.875307 , 28.605
97.96234 , 97.8695
12.894617 , 13.3795
18.103159 , 18.5829
4.2915154 , 4.2183
3.5719337 , 3.4807
1.2927647 , 1.0415
4.8576946 , 4.7545
5.9576807 , 5.9359
36.98825 , 34.7328
6.278964 , 6.3359
15.18374 , 15.3616
5.7569084 , 5.7719
15.11214 , 15.2208
3.586545 , 3.6243
3.6198683 , 3.5932
23.037212 , 23.9504
3.6148214 , 3.5766
16.628002 , 16.6475
1.4019566 , 1.1981
5.7552395 , 5.6015
43.771717 , 43.847
4.5662003 , 4.4135
3.9955463 , 3.9641
18.54911 , 19.1709
19.94021 , 20.036
6.1684504 , 5.9164
28.549114 , 26.4758
4.593992 , 4.5578
1.2426491 , 1.1294
15.978471 , 16.4275
3.6958866 , 3.6449
5.006114 , 5.1647
4.2681303 , 4.1624
29.055962 , 28.5842
5.8442984 , 5.8081
12.976918 , 12.7857
1.548254 , 2.3553
21.33271 , 22.7686
9.259375 , 10.0477
3.6284866 , 3.5929
6.762026 , 7.0419
16.828884 , 17.0938
13.8917675 , 13.8059
18.663607 , 18.6739
4.703355 , 4.7664
4.158762 , 4.1386
104.10863 , 95.512
12.570489 , 12.8266
16.888964 , 16.9212
4.515975 , 4.6114
16.348774 , 17.0034
4.334859 , 4.3595
14.870964 , 15.2303
2.7503605 , 2.8208
34.004013 , 33.2427
14.99065 , 15.2038
1.1781769 , 1.0154
10.600502 , 10.8122
19.643671 , 19.3665
5.4120903 , 5.444
24.076931 , 23.9959
29.806614 , 29.8823
4.674778 , 4.84
16.453442 , 16.9427
3.7055502 , 3.6034
5.442973 , 5.5675
3.7861385 , 3.5974
3.560112 , 3.6453
42.142525 , 42.3751
16.965761 , 17.2908
15.427505 , 15.7579
6.1716013 , 6.19
21.136566 , 20.8219
4.7557087 , 4.6836
3.7441425 , 3.7311
4.0123024 , 4.217
35.782913 , 34.4399
3.328847 , 3.5945
4.177931 , 4.1324
3.719883 , 3.7856
5.38453 , 5.4621
4.7025747 , 4.7079
3.6617355 , 3.6438
1.7305222 , 1.6584
23.035667 , 23.9713
1.9218063 , 1.7976
RMSE:  0.6695703722600665  MAPE: 0.02746813285858805
5: ground truth total-  210  predicted total -  210
100: ground truth total-  320  predicted total -  320
 more 100: ground truth total -  6  predicted total -  6
