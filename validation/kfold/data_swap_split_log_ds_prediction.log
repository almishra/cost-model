['Outer', 'Inner', 'Reduction', 'VarDecl', 'refExpr', 'intLiteral', 'floatLiteral', 'mem_to', 'mem_from', 'add_sub_int', 'add_sub_double', 'mul_int', 'mul_double', 'div_int', 'div_double', 'assign_int', 'assign_double', 'log_Outer', 'log_Inner', 'log_VarDecl', 'log_refExpr', 'log_intLiteral', 'log_floatLiteral', 'log_mem_to', 'log_mem_from', 'log_add_sub_int', 'log_add_sub_double', 'log_mul_int', 'log_mul_double', 'log_div_int', 'log_div_double', 'log_assign_int', 'log_assign_double', 'runtimes']
2034
34
<class 'numpy.dtype'> float64
2034
train batches:  92  validate samples: 162  test samples: 406
Epoch [0/75], Batch loss: 32.151
Epoch: 0 RMSE:  19.494849819317423  MAPE: 0.8142028918261954  L2+L1 loss: 9.658
Epoch [1/75], Batch loss: 25.209
Epoch: 1 RMSE:  14.505778879252851  MAPE: 0.8030875764427295  L2+L1 loss: 7.105
Epoch [2/75], Batch loss: 22.221
Epoch: 2 RMSE:  13.3912201222624  MAPE: 1.853921707595128  L2+L1 loss: 6.763
Epoch [3/75], Batch loss: 22.263
Epoch: 3 RMSE:  13.460900500184163  MAPE: 2.575136180137235  L2+L1 loss: 7.719
Epoch [4/75], Batch loss: 20.775
Epoch: 4 RMSE:  12.089068491852792  MAPE: 1.7132708517923576  L2+L1 loss: 6.44
Epoch [5/75], Batch loss: 19.628
Epoch: 5 RMSE:  10.927400065216261  MAPE: 2.3538280061670642  L2+L1 loss: 6.426
Epoch [6/75], Batch loss: 20.11
Epoch: 6 RMSE:  12.200671532222064  MAPE: 0.6080185832965936  L2+L1 loss: 4.978
Epoch [7/75], Batch loss: 19.917
Epoch: 7 RMSE:  8.035165770283228  MAPE: 0.562439371598182  L2+L1 loss: 4.147
Epoch [8/75], Batch loss: 43.158
Epoch: 8 RMSE:  22.755737328111476  MAPE: 9.364974290940458  L2+L1 loss: 17.084
Epoch [9/75], Batch loss: 38.588
Epoch: 9 RMSE:  13.67079602978538  MAPE: 2.9904425923493125  L2+L1 loss: 8.418
Epoch [10/75], Batch loss: 21.858
Epoch: 10 RMSE:  13.783423049775713  MAPE: 3.1534006847325444  L2+L1 loss: 8.727
Epoch [11/75], Batch loss: 21.729
Epoch: 11 RMSE:  13.821648663055697  MAPE: 3.218834293051673  L2+L1 loss: 8.718
Epoch [12/75], Batch loss: 21.776
Epoch: 12 RMSE:  13.417047544363662  MAPE: 2.448557962399829  L2+L1 loss: 7.51
Epoch [13/75], Batch loss: 28.776
Epoch: 13 RMSE:  13.791239426032027  MAPE: 3.108443255023066  L2+L1 loss: 8.787
Epoch [14/75], Batch loss: 22.132
Epoch: 14 RMSE:  13.643255554762282  MAPE: 2.9200707414811893  L2+L1 loss: 8.369
Epoch [15/75], Batch loss: 22.914
Epoch: 15 RMSE:  14.493420737077528  MAPE: 3.8373250197609527  L2+L1 loss: 10.449
Epoch [16/75], Batch loss: 22.214
Epoch: 16 RMSE:  13.519885012247343  MAPE: 2.704512375116146  L2+L1 loss: 7.954
Epoch [17/75], Batch loss: 42.587
Epoch: 17 RMSE:  14.040191543520585  MAPE: 0.7101124723394606  L2+L1 loss: 6.477
Epoch [18/75], Batch loss: 20.886
Epoch: 18 RMSE:  12.461152921782292  MAPE: 0.7153751915823843  L2+L1 loss: 5.032
Epoch [19/75], Batch loss: 19.975
Epoch: 19 RMSE:  11.982167669532144  MAPE: 0.5196858020330339  L2+L1 loss: 4.934
Epoch [20/75], Batch loss: 18.509
Epoch: 20 RMSE:  11.830056067775521  MAPE: 0.7585822199241418  L2+L1 loss: 5.521
Epoch [21/75], Batch loss: 20.793
Epoch: 21 RMSE:  12.23486829296645  MAPE: 0.784122992851188  L2+L1 loss: 6.385
Epoch [22/75], Batch loss: 20.043
Epoch: 22 RMSE:  12.383902962756805  MAPE: 0.8391133298656369  L2+L1 loss: 6.759
Epoch [23/75], Batch loss: 20.893
Epoch: 23 RMSE:  13.350043024903783  MAPE: 2.639709852112954  L2+L1 loss: 9.838
Epoch [24/75], Batch loss: 20.691
Epoch: 24 RMSE:  13.03176800411154  MAPE: 2.1001621825359016  L2+L1 loss: 8.931
Epoch [25/75], Batch loss: 24.037
Epoch: 25 RMSE:  16.68385804767053  MAPE: 5.267597580256787  L2+L1 loss: 14.025
Epoch [26/75], Batch loss: 24.264
Epoch: 26 RMSE:  14.77124033316119  MAPE: 4.058155482183892  L2+L1 loss: 10.989
Epoch [27/75], Batch loss: 22.279
Epoch: 27 RMSE:  14.148941643331645  MAPE: 3.5255790324036047  L2+L1 loss: 9.722
Epoch [28/75], Batch loss: 22.426
Epoch: 28 RMSE:  13.869775458627593  MAPE: 3.224669885070073  L2+L1 loss: 9.022
Epoch [29/75], Batch loss: 34.687
Epoch: 29 RMSE:  13.768780712239192  MAPE: 3.1321179242399304  L2+L1 loss: 8.744
Epoch [30/75], Batch loss: 22.698
Epoch: 30 RMSE:  13.734481606590302  MAPE: 3.1021364631316533  L2+L1 loss: 8.615
Epoch [31/75], Batch loss: 22.689
Epoch: 31 RMSE:  13.554281255850118  MAPE: 2.946867068426236  L2+L1 loss: 8.399
Epoch [32/75], Batch loss: 19.511
Epoch: 32 RMSE:  12.06645509184973  MAPE: 0.4970108520963167  L2+L1 loss: 4.709
Epoch [33/75], Batch loss: 19.117
Epoch: 33 RMSE:  12.033256428120742  MAPE: 0.5059837048740695  L2+L1 loss: 4.748
Epoch [34/75], Batch loss: 19.525
Epoch: 34 RMSE:  11.974419777735818  MAPE: 0.43897254446530465  L2+L1 loss: 4.598
Epoch [35/75], Batch loss: 19.076
Epoch: 35 RMSE:  11.90385513897808  MAPE: 0.4653836312726153  L2+L1 loss: 4.639
Epoch [36/75], Batch loss: 19.462
Epoch: 36 RMSE:  11.761519342745501  MAPE: 0.3408475130549766  L2+L1 loss: 4.235
Epoch [37/75], Batch loss: 18.258
Epoch: 37 RMSE:  11.677269135257934  MAPE: 0.4124438873350835  L2+L1 loss: 4.164
Epoch [38/75], Batch loss: 18.743
Epoch: 38 RMSE:  5.9706372289119445  MAPE: 0.6426166223187628  L2+L1 loss: 4.243
Epoch [39/75], Batch loss: 13.787
Epoch: 39 RMSE:  11.783818036295125  MAPE: 0.32987492758029296  L2+L1 loss: 4.151
Epoch [40/75], Batch loss: 19.499
Epoch: 40 RMSE:  11.64861826903397  MAPE: 0.30084724944646435  L2+L1 loss: 3.994
Epoch [41/75], Batch loss: 19.303
Epoch: 41 RMSE:  11.46980292904799  MAPE: 0.34790572366487876  L2+L1 loss: 3.748
Epoch [42/75], Batch loss: 12.875
Epoch: 42 RMSE:  46.99728821390282  MAPE: 1.9949971048704005  L2+L1 loss: 21.355
Epoch [43/75], Batch loss: 23.596
Epoch: 43 RMSE:  27.18561524948329  MAPE: 1.35914199447116  L2+L1 loss: 14.852
Epoch [44/75], Batch loss: 25.97
Epoch: 44 RMSE:  11.288888519761773  MAPE: 0.24125952144020602  L2+L1 loss: 3.537
Epoch [45/75], Batch loss: 18.831
Epoch: 45 RMSE:  10.927687769402059  MAPE: 0.14561626980081144  L2+L1 loss: 2.907
Epoch [46/75], Batch loss: 12.364
Epoch: 46 RMSE:  4.761148463644566  MAPE: 0.3186344050225142  L2+L1 loss: 2.749
Epoch [47/75], Batch loss: 5.723
Epoch: 47 RMSE:  2.999621595325675  MAPE: 0.6204898704877686  L2+L1 loss: 2.282
Epoch [48/75], Batch loss: 9.445
Epoch: 48 RMSE:  1.6365526438714297  MAPE: 0.1485413263021997  L2+L1 loss: 1.342
Epoch [49/75], Batch loss: 3.865
Epoch: 49 RMSE:  1.210376753893332  MAPE: 0.11840461237665975  L2+L1 loss: 1.039
Epoch [50/75], Batch loss: 14.445
Epoch: 50 RMSE:  10.043481366427432  MAPE: 2.2864523680599014  L2+L1 loss: 7.085
Epoch [51/75], Batch loss: 6.396
Epoch: 51 RMSE:  2.3912905392214534  MAPE: 0.420837060824582  L2+L1 loss: 1.921
Epoch [52/75], Batch loss: 2.46
Epoch: 52 RMSE:  1.8176818688446064  MAPE: 0.21748594284554248  L2+L1 loss: 1.487
Epoch [53/75], Batch loss: 3.333
Epoch: 53 RMSE:  4.773839148524379  MAPE: 1.1868643033840502  L2+L1 loss: 3.335
Epoch [54/75], Batch loss: 4.651
Epoch: 54 RMSE:  2.944903963584268  MAPE: 0.38721196753710857  L2+L1 loss: 2.129
Epoch [55/75], Batch loss: 4.179
Epoch: 55 RMSE:  2.5203425358893177  MAPE: 0.1468805367506077  L2+L1 loss: 1.467
Epoch [56/75], Batch loss: 3.685
Epoch: 56 RMSE:  1.0835395919496813  MAPE: 0.09698295505420518  L2+L1 loss: 0.944
Epoch [57/75], Batch loss: 2.097
Epoch: 57 RMSE:  1.2946999294283594  MAPE: 0.08799318767312493  L2+L1 loss: 0.943
Epoch [58/75], Batch loss: 5.205
Epoch: 58 RMSE:  11.603329334063211  MAPE: 0.4884160089785185  L2+L1 loss: 4.256
Epoch [59/75], Batch loss: 9.912
Epoch: 59 RMSE:  4.011737596786683  MAPE: 0.21762480443650012  L2+L1 loss: 2.119
Epoch [60/75], Batch loss: 2.859
Epoch: 60 RMSE:  1.9886175964881712  MAPE: 0.11498805727481302  L2+L1 loss: 1.196
Epoch [61/75], Batch loss: 1.811
Epoch: 61 RMSE:  1.559146245602345  MAPE: 0.12275141615687912  L2+L1 loss: 1.179
Epoch [62/75], Batch loss: 1.714
Epoch: 62 RMSE:  2.2448161079332603  MAPE: 0.12167764717190138  L2+L1 loss: 1.259
Epoch [63/75], Batch loss: 1.827
Epoch: 63 RMSE:  1.3827716974629587  MAPE: 0.13958134347628692  L2+L1 loss: 1.122
Epoch [64/75], Batch loss: 1.805
Epoch: 64 RMSE:  1.5222009233433231  MAPE: 0.09825612621285422  L2+L1 loss: 1.068
Epoch [65/75], Batch loss: 1.562
Epoch: 65 RMSE:  1.2458518158847545  MAPE: 0.12811183397668144  L2+L1 loss: 1.054
Epoch [66/75], Batch loss: 1.328
Epoch: 66 RMSE:  1.096023356769827  MAPE: 0.0856087157889039  L2+L1 loss: 0.898
Epoch [67/75], Batch loss: 1.311
Epoch: 67 RMSE:  1.0044985954489702  MAPE: 0.07583732713689943  L2+L1 loss: 0.836
Epoch [68/75], Batch loss: 1.326
Epoch: 68 RMSE:  1.4813858205770698  MAPE: 0.07206454643736217  L2+L1 loss: 0.905
Epoch [69/75], Batch loss: 1.333
Epoch: 69 RMSE:  1.0304747036735182  MAPE: 0.07161587218999144  L2+L1 loss: 0.79
Epoch [70/75], Batch loss: 1.113
Epoch: 70 RMSE:  0.8148904635302221  MAPE: 0.06838533500830314  L2+L1 loss: 0.743
Epoch [71/75], Batch loss: 1.209
Epoch: 71 RMSE:  0.7972699950848889  MAPE: 0.15025526370822267  L2+L1 loss: 0.864
Epoch [72/75], Batch loss: 1.054
Epoch: 72 RMSE:  0.6857220942258703  MAPE: 0.07257707661790398  L2+L1 loss: 0.665
Epoch [73/75], Batch loss: 1.225
Epoch: 73 RMSE:  0.8329567233517599  MAPE: 0.04694797196396946  L2+L1 loss: 0.619
Epoch [74/75], Batch loss: 0.946
Epoch: 74 RMSE:  0.9020871659057547  MAPE: 0.04667021174362888  L2+L1 loss: 0.65


Evaluating Model.......
Best Model - RMSE: inf  MAPE: inf  L2+L1- inf
predicted_runtime, ground_truth
18.699806 , 17.8954
1.8826199 , 1.872
8.759102 , 9.4362
1.0463057 , 1.0251
9.353628 , 8.3185
7.2637105 , 7.7206
1.0780697 , 1.0619
1.3930302 , 1.3548
6.0938454 , 5.8752
5.5315475 , 5.3308
2.5302792 , 3.3614
0.96366215 , 1.0437
3.6088123 , 3.5703
1.7882042 , 1.6554
11.5384035 , 10.8351
12.008081 , 11.4344
32.676395 , 31.1675
28.272575 , 27.5302
12.469946 , 12.1057
29.710606 , 28.0629
6.032852 , 5.9047
1.4480467 , 1.3533
3.268033 , 3.3893
5.2606907 , 4.4959
19.395145 , 19.7984
2.371274 , 2.6929
2.2883205 , 2.4864
1.3997746 , 1.3474
2.0681982 , 2.0734
1.2581863 , 1.1565
7.099328 , 6.904
10.061439 , 9.6471
1.6173754 , 1.5359
1.7488317 , 1.9174
1.6419191 , 1.5902
4.502716 , 4.1801
2.2849722 , 2.1466
7.868849 , 7.574
8.044691 , 7.5758
1.0624819 , 1.0253
4.6205654 , 5.524
1.545269 , 1.4801
9.1040745 , 8.8407
10.753131 , 10.5474
1.2897654 , 1.0905
16.14778 , 16.1214
9.6161 , 9.9315
8.575935 , 8.4245
1.0672865 , 1.0373
7.943004 , 7.9113
11.680464 , 11.4174
9.018688 , 9.2554
9.406338 , 10.1141
4.575617 , 5.0858
6.753086 , 6.7016
28.00542 , 27.5439
17.359068 , 17.7166
24.007542 , 22.3875
5.767436 , 5.5283
212.92502 , 210.1925
12.054519 , 10.1814
8.772067 , 8.5927
1.26303 , 1.2522
1.5605288 , 1.4714
1.5945368 , 1.4971
1.6679316 , 2.1231
9.051798 , 8.9105
15.124269 , 14.4195
2.0086164 , 1.9133
2.8695908 , 2.5769
1.8174715 , 1.7869
20.19215 , 19.6484
21.916159 , 20.8708
1.5924463 , 1.5094
7.1885085 , 7.5454
1.2104664 , 1.1928
9.133145 , 9.3131
14.34072 , 14.2759
7.6810803 , 7.7914
6.708398 , 6.5309
7.4630146 , 7.4972
1.103198 , 1.08
10.409708 , 10.4886
8.315779 , 7.9229
1.1424007 , 1.1011
1.6619396 , 1.7224
17.795176 , 17.1683
1.831912 , 1.8402
11.010363 , 9.2676
1.8235779 , 1.8103
3.2668934 , 3.0797
29.599041 , 29.0779
1.3321781 , 1.3102
1.7504826 , 1.9428
1.6450939 , 1.6138
5.5875225 , 5.371
8.498948 , 8.3536
7.4429655 , 7.2685
1.9088144 , 2.2447
8.108696 , 8.3253
20.098738 , 19.7356
3.2869625 , 3.2692
1.492651 , 1.4462
1.9928389 , 1.8063
8.991922 , 9.0157
5.4017506 , 4.9421
1.0855513 , 1.0355
3.8284311 , 4.0669
1.163743 , 1.0676
12.720183 , 12.8039
1.5693235 , 1.5245
1.2712679 , 1.244
1.0217323 , 1.0099
9.282945 , 9.6968
10.446595 , 10.2845
12.06905 , 11.3669
2.7950897 , 2.4404
1.3324089 , 1.2741
131.09003 , 126.6888
5.9507484 , 5.8973
8.197039 , 8.2321
1.4507599 , 1.7746
8.435172 , 8.4389
2.9191456 , 3.5587
4.5930347 , 3.6141
3.106595 , 2.7653
5.1807213 , 5.3008
1.0072126 , 1.0111
0.0 , 3.7554
18.10239 , 17.8948
1.7676296 , 1.7369
1.0846958 , 1.0609
6.964053 , 5.9456
5.792925 , 5.2836
8.441511 , 8.087
2.5771723 , 1.8524
15.783208 , 15.5747
6.9249463 , 6.6269
11.691452 , 11.5173
1.8423119 , 1.7721
11.001441 , 11.0879
1.3665981 , 1.3328
1.7639923 , 1.6081
1.4692631 , 1.4228
22.810917 , 22.6015
2.2688904 , 2.3113
1.3997698 , 1.3435
1.2838631 , 1.2359
7.4958277 , 7.788
98.27401 , 95.7928
8.5006275 , 8.5526
2.210555 , 2.0823
1.2066097 , 1.0677
1.1969051 , 1.042
1.5054417 , 1.3977
5.145072 , 5.066
16.498148 , 17.4541
6.087078 , 6.3748
5.1066933 , 4.9776
1.4982052 , 1.2292
1.4402351 , 1.2821
6.712939 , 7.3586
12.514477 , 12.4139
2.8976183 , 2.9124
25.46384 , 24.5365
1.1556978 , 1.1124
10.212635 , 9.6962
10.453905 , 10.0977
7.2589035 , 7.4994
1.1735954 , 1.1355
8.986923 , 8.9943
16.427528 , 14.6026
9.089711 , 9.2501
5.697834 , 5.4483
1.4425459 , 1.3948
1.1225834 , 1.2663
6.473447 , 6.6415
6.139762 , 6.1822
2.9003868 , 2.9519
6.7036963 , 6.0875
6.812525 , 7.4672
1.9256582 , 1.9128
7.386463 , 7.2605
6.7845106 , 6.4911
7.201989 , 6.8395
19.57855 , 19.2598
1.447978 , 1.4017
9.352669 , 9.1658
288.85825 , 282.24
4.4531565 , 4.1396
8.093675 , 7.8637
9.2109585 , 9.0829
0.11507797 , 1.7566
8.988385 , 9.2366
1.2557077 , 1.1923
6.0129194 , 5.7858
2.5751324 , 2.6196
7.379226 , 7.5509
5.1287804 , 5.5108
10.169762 , 10.9139
1.3007717 , 1.2744
1.53475 , 1.4671
8.459327 , 8.623
1.5682507 , 1.5615
11.547413 , 10.741
3.6064787 , 3.7415
3.6795454 , 4.7473
1.4762115 , 1.4437
4.35791 , 4.3508
16.412048 , 16.1532
13.784685 , 13.3214
8.774996 , 8.6789
8.544661 , 8.8161
2.2584524 , 2.145
3.9538946 , 3.3741
2.166606 , 2.2138
7.1694355 , 7.2466
16.533617 , 16.0622
24.46127 , 24.1471
10.17504 , 10.1919
15.1279125 , 15.1364
8.804591 , 8.9067
13.445687 , 14.1808
1.3875618 , 1.3223
8.919942 , 9.0117
10.124558 , 10.7465
2.185748 , 1.832
4.6254864 , 5.0376
7.2353926 , 7.1357
16.185518 , 16.651
1.5494423 , 1.5006
6.7812786 , 6.8798
1.4163942 , 1.345
19.09445 , 18.4566
2.907939 , 3.0971
1.0782099 , 1.056
0.61574936 , 1.5409
1.2882729 , 1.2863
13.944799 , 15.1822
9.785301 , 10.2347
5.805168 , 5.9323
1.3346996 , 1.2672
3.1440287 , 3.0507
12.137446 , 11.666
4.5040007 , 4.3897
16.501402 , 16.9204
2.9567099 , 3.2072
1.4179401 , 1.3807
1.8360844 , 1.836
12.207577 , 12.1701
8.533073 , 9.0163
120.81463 , 114.941
3.7826176 , 3.3787
3.8545532 , 2.4635
3.2335854 , 3.4429
3.2461424 , 2.5955
9.409214 , 9.8953
12.647592 , 12.6061
13.557265 , 13.823
1.2976122 , 1.2655
8.145353 , 7.9598
7.6719584 , 7.6796
7.562639 , 7.4853
1.1119862 , 1.0928
3.1585999 , 3.1065
8.685795 , 8.7628
6.844743 , 6.8252
1.0840416 , 1.067
1.4292898 , 1.3723
4.006051 , 3.838
12.043866 , 12.0015
3.0110054 , 3.2296
6.604411 , 6.5055
6.4524384 , 6.6197
1.2646866 , 1.3977
4.0632725 , 4.8338
1.2665873 , 1.2075
8.368102 , 8.1444
2.9845295 , 2.6464
9.328335 , 9.2831
3.0896177 , 2.6755
1.320694 , 1.1512
6.7159896 , 6.7853
25.24719 , 23.8859
11.594 , 10.7328
4.1694183 , 4.1227
3.1381435 , 2.5281
8.428225 , 8.6146
9.811964 , 10.1609
11.998756 , 10.9583
7.345524 , 7.0991
24.60009 , 24.1971
6.954153 , 6.9095
8.295485 , 8.0312
1.2544222 , 1.216
1.4198322 , 1.1629
8.046996 , 8.1906
4.5005493 , 4.5619
8.316708 , 6.9055
1.3137846 , 1.2311
1.6891823 , 1.8259
1.1392136 , 1.1195
2.1994963 , 2.2743
1.6203356 , 1.6195
1.5834379 , 1.4239
7.642915 , 7.6172
6.216733 , 5.9348
39.136955 , 36.2469
16.571709 , 16.8099
9.610186 , 9.8434
1.4010439 , 1.323
16.757427 , 17.764
13.753865 , 13.1611
2.8332014 , 2.9059
8.899104 , 9.0094
10.289177 , 10.5458
1.0860958 , 1.0859
11.357296 , 11.2859
7.5720496 , 7.599
3.8236609 , 2.8587
10.133492 , 10.3367
22.225866 , 21.15
4.9604645 , 5.51
4.7813883 , 4.6391
1.3693981 , 1.2984
9.745422 , 10.1648
15.932814 , 15.1001
7.2589827 , 7.1137
2.5328636 , 2.1793
7.595572 , 7.4297
8.183438 , 8.2838
4.9417286 , 5.1217
1.7729568 , 1.8181
1.628892 , 1.617
2.327692 , 2.4123
20.994331 , 20.8933
4.5623035 , 5.1611
8.07619 , 8.1574
22.016638 , 20.9479
1.537117 , 1.4592
96.79807 , 93.8928
1.75844 , 1.6786
1.0077162 , 1.0575
1.7384148 , 1.707
1.5840302 , 1.3039
1.8650837 , 1.9499
20.32923 , 19.6912
9.232764 , 9.3263
10.289505 , 10.1248
26.22558 , 24.8986
1.3507662 , 1.2914
9.422294 , 9.7905
1.1297312 , 1.1018
7.610841 , 8.1039
1.3287239 , 1.2693
7.335071 , 7.3044
8.9379015 , 8.7864
1.8352747 , 1.8933
1.2386637 , 1.2029
1.3491478 , 1.2857
11.762694 , 12.7993
8.263543 , 8.0869
1.5397205 , 1.5224
1.9231939 , 1.9305
229.67838 , 226.8208
17.381565 , 16.882
26.993628 , 26.1177
119.34537 , 114.1179
5.2866964 , 5.6416
1.3130426 , 1.2541
106.99541 , 104.6118
0.78300667 , 1.0377
6.165945 , 5.9274
2.4217644 , 2.6668
7.5802984 , 7.7937
6.0325155 , 6.1256
2.3258429 , 1.7642
22.033863 , 21.1894
1.4912376 , 1.4862
9.863327 , 10.2112
1.2388573 , 1.1951
1.1832142 , 1.1663
21.448088 , 19.708
8.285524 , 8.0321
5.871109 , 5.0201
9.001169 , 8.8967
2.4468126 , 2.4961
14.2651825 , 13.0348
1.3892069 , 1.3595
21.981308 , 21.7515
1.4396553 , 1.426
1.5438337 , 1.4921
12.0929365 , 13.1679
2.5313215 , 1.8636
8.200746 , 6.9223
1.3827877 , 1.3771
7.6525106 , 6.8008
8.935316 , 7.8304
5.912135 , 5.4984
6.066558 , 6.2009
1.1698389 , 1.1327
1.2145252 , 1.1571
23.459597 , 22.9017
308.40057 , 300.9403
131.17255 , 126.8923
1.1380911 , 1.0063
RMSE:  0.919641405630263  MAPE: 0.059610726835684656
5: ground truth total-  183  predicted total -  182
100: ground truth total-  214  predicted total -  214
 more 100: ground truth total -  9  predicted total -  9
