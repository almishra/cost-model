['Outer', 'Inner', 'Reduction', 'VarDecl', 'refExpr', 'intLiteral', 'floatLiteral', 'mem_to', 'mem_from', 'add_sub_int', 'add_sub_double', 'mul_int', 'mul_double', 'div_int', 'div_double', 'assign_int', 'assign_double', 'log_Outer', 'log_Inner', 'log_VarDecl', 'log_refExpr', 'log_intLiteral', 'log_floatLiteral', 'log_mem_to', 'log_mem_from', 'log_add_sub_int', 'log_add_sub_double', 'log_mul_int', 'log_mul_double', 'log_div_int', 'log_div_double', 'log_assign_int', 'log_assign_double', 'runtimes']
1461
34
<class 'numpy.dtype'> float64
1461
train batches:  66  validate samples: 116  test samples: 292
Epoch [0/75], Batch loss: 37.919
Epoch: 0 RMSE:  0.6652360534177105  MAPE: 0.6564440043644283  L2+L1 loss: 0.544
Epoch [1/75], Batch loss: 0.594
Epoch: 1 RMSE:  0.6151581473983316  MAPE: 1.3457850450990534  L2+L1 loss: 0.564
Epoch [2/75], Batch loss: 0.503
Epoch: 2 RMSE:  0.6072620170053599  MAPE: 1.0856025580433217  L2+L1 loss: 0.521
Epoch [3/75], Batch loss: 1.621
Epoch: 3 RMSE:  3.2686025775843213  MAPE: 11.810105309198075  L2+L1 loss: 3.156
Epoch [4/75], Batch loss: 0.97
Epoch: 4 RMSE:  0.7467041563821133  MAPE: 2.8818335090855696  L2+L1 loss: 0.892
Epoch [5/75], Batch loss: 1.61
Epoch: 5 RMSE:  0.6373440099866571  MAPE: 1.7541565973307227  L2+L1 loss: 0.653
Epoch [6/75], Batch loss: 16.133
Epoch: 6 RMSE:  53.8662728228498  MAPE: 267.8314372147553  L2+L1 loss: 39.307
Epoch [7/75], Batch loss: 7.723
Epoch: 7 RMSE:  4.098652857044524  MAPE: 7.166650550284987  L2+L1 loss: 1.995
Epoch [8/75], Batch loss: 3.595
Epoch: 8 RMSE:  2.139473312482794  MAPE: 8.226851491612518  L2+L1 loss: 2.041
Epoch [9/75], Batch loss: 1.428
Epoch: 9 RMSE:  1.1411357157178068  MAPE: 2.713089127160843  L2+L1 loss: 1.056
Epoch [10/75], Batch loss: 0.833
Epoch: 10 RMSE:  0.6077266656121303  MAPE: 0.8570289803768729  L2+L1 loss: 0.465
Epoch [11/75], Batch loss: 0.6
Epoch: 11 RMSE:  0.5866006056792387  MAPE: 0.7255408500110545  L2+L1 loss: 0.463
Epoch [12/75], Batch loss: 0.446
Epoch: 12 RMSE:  0.584696328024806  MAPE: 0.46043919090358615  L2+L1 loss: 0.386
Epoch [13/75], Batch loss: 0.836
Epoch: 13 RMSE:  0.6381877941425127  MAPE: 1.1523403805817505  L2+L1 loss: 0.555
Epoch [14/75], Batch loss: 0.704
Epoch: 14 RMSE:  0.6078112515442947  MAPE: 0.9352246793764141  L2+L1 loss: 0.5
Epoch [15/75], Batch loss: 0.46
Epoch: 15 RMSE:  0.6077902085656249  MAPE: 1.1200213441325393  L2+L1 loss: 0.526
Epoch [16/75], Batch loss: 0.54
Epoch: 16 RMSE:  0.6226307462618713  MAPE: 1.0058577061671634  L2+L1 loss: 0.549
Epoch [17/75], Batch loss: 3.462
Epoch: 17 RMSE:  0.6494222480532611  MAPE: 1.919794435169758  L2+L1 loss: 0.689
Epoch [18/75], Batch loss: 0.489
Epoch: 18 RMSE:  0.6182592910040066  MAPE: 1.4170190759582235  L2+L1 loss: 0.578
Epoch [19/75], Batch loss: 0.8
Epoch: 19 RMSE:  0.7170432353575429  MAPE: 2.6411970257151993  L2+L1 loss: 0.833
Epoch [20/75], Batch loss: 0.832
Epoch: 20 RMSE:  0.6149138656670257  MAPE: 1.3165493135731299  L2+L1 loss: 0.566
Epoch [21/75], Batch loss: 0.468
Epoch: 21 RMSE:  0.6084749922141419  MAPE: 1.126052253773438  L2+L1 loss: 0.528
Epoch [22/75], Batch loss: 0.452
Epoch: 22 RMSE:  0.6060296900439337  MAPE: 0.9990675413215337  L2+L1 loss: 0.505
Epoch [23/75], Batch loss: 0.46
Epoch: 23 RMSE:  0.6065286866485602  MAPE: 1.0292108550455652  L2+L1 loss: 0.511
Epoch [24/75], Batch loss: 0.476
Epoch: 24 RMSE:  0.6104020453349276  MAPE: 1.21296041616126  L2+L1 loss: 0.54
Epoch [25/75], Batch loss: 0.47
Epoch: 25 RMSE:  1.0453919873699842  MAPE: 1.4093658981352326  L2+L1 loss: 0.677
Epoch [26/75], Batch loss: 0.532
Epoch: 26 RMSE:  0.6089041077894989  MAPE: 1.1599273930636356  L2+L1 loss: 0.533
Epoch [27/75], Batch loss: 0.458
Epoch: 27 RMSE:  0.6124031546926704  MAPE: 1.2737782892926945  L2+L1 loss: 0.552
Epoch [28/75], Batch loss: 0.479
Epoch: 28 RMSE:  0.6225580411222177  MAPE: 1.505249463414692  L2+L1 loss: 0.597
Epoch [29/75], Batch loss: 0.486
Epoch: 29 RMSE:  0.6098817602342522  MAPE: 0.6624491567845111  L2+L1 loss: 0.453
Epoch [30/75], Batch loss: 0.468
Epoch: 30 RMSE:  0.6097026204416002  MAPE: 1.1893341549943581  L2+L1 loss: 0.537
Epoch [31/75], Batch loss: 0.472
Epoch: 31 RMSE:  0.6118266233649865  MAPE: 1.2571679937434717  L2+L1 loss: 0.549
Epoch [32/75], Batch loss: 0.476
Epoch: 32 RMSE:  0.609659146616987  MAPE: 1.1878020017510542  L2+L1 loss: 0.537
Epoch [33/75], Batch loss: 0.463
Epoch: 33 RMSE:  0.6107305481961788  MAPE: 1.2235703118855032  L2+L1 loss: 0.542
Epoch [34/75], Batch loss: 0.461
Epoch: 34 RMSE:  0.6126077332972321  MAPE: 1.279504552582952  L2+L1 loss: 0.552
Epoch [35/75], Batch loss: 0.473
Epoch: 35 RMSE:  0.6080376998063232  MAPE: 1.1238322102610032  L2+L1 loss: 0.527
Epoch [36/75], Batch loss: 0.454
Epoch: 36 RMSE:  0.6089083052937769  MAPE: 1.1600899364261623  L2+L1 loss: 0.533
Epoch [37/75], Batch loss: 0.461
Epoch: 37 RMSE:  0.6123019118146777  MAPE: 1.2709130978855308  L2+L1 loss: 0.551
Epoch [38/75], Batch loss: 0.604
Epoch: 38 RMSE:  0.6212461760251268  MAPE: 1.4793573160344315  L2+L1 loss: 0.591
Epoch [39/75], Batch loss: 0.484
Epoch: 39 RMSE:  0.6128227418213412  MAPE: 1.2854347947316667  L2+L1 loss: 0.553
Epoch [40/75], Batch loss: 0.465
Epoch: 40 RMSE:  0.608877038169093  MAPE: 1.1588766791799665  L2+L1 loss: 0.533
Epoch [41/75], Batch loss: 0.443
Epoch: 41 RMSE:  0.6114786000964862  MAPE: 1.2467735960584796  L2+L1 loss: 0.546
Epoch [42/75], Batch loss: 0.617
Epoch: 42 RMSE:  0.6059122982688969  MAPE: 0.8403817139870836  L2+L1 loss: 0.478
Epoch [43/75], Batch loss: 0.448
Epoch: 43 RMSE:  0.6058701088467516  MAPE: 0.979537656609866  L2+L1 loss: 0.502
Epoch [44/75], Batch loss: 0.47
Epoch: 44 RMSE:  0.6073781598600303  MAPE: 1.0917729011770796  L2+L1 loss: 0.521
Epoch [45/75], Batch loss: 2.411
Epoch: 45 RMSE:  0.6093128929256836  MAPE: 1.1753032754094568  L2+L1 loss: 0.535
Epoch [46/75], Batch loss: 0.45
Epoch: 46 RMSE:  0.6095757529287307  MAPE: 1.184839992340417  L2+L1 loss: 0.537
Epoch [47/75], Batch loss: 0.449
Epoch: 47 RMSE:  0.6097158859311  MAPE: 1.1898000672692783  L2+L1 loss: 0.537
Epoch [48/75], Batch loss: 0.458
Epoch: 48 RMSE:  0.6099124029404186  MAPE: 1.1972973532715556  L2+L1 loss: 0.538
Epoch [49/75], Batch loss: 0.473
Epoch: 49 RMSE:  0.6094111431908826  MAPE: 1.1797967347961544  L2+L1 loss: 0.536
Epoch [50/75], Batch loss: 0.465
Epoch: 50 RMSE:  0.6092708566726046  MAPE: 1.1767598460467505  L2+L1 loss: 0.535
Epoch [51/75], Batch loss: 0.563
Epoch: 51 RMSE:  0.6080976582851007  MAPE: 1.1294320507803732  L2+L1 loss: 0.528
Epoch [52/75], Batch loss: 0.465
Epoch: 52 RMSE:  0.611353147707987  MAPE: 1.239320498620036  L2+L1 loss: 0.545
Epoch [53/75], Batch loss: 0.462
Epoch: 53 RMSE:  0.6122926902805143  MAPE: 1.2706510711879173  L2+L1 loss: 0.551
Epoch [54/75], Batch loss: 0.477
Epoch: 54 RMSE:  0.6123903478835935  MAPE: 1.2734170195152315  L2+L1 loss: 0.551
Epoch [55/75], Batch loss: 0.459
Epoch: 55 RMSE:  0.6098762068516582  MAPE: 1.195373076218501  L2+L1 loss: 0.538
Epoch [56/75], Batch loss: 0.473
Epoch: 56 RMSE:  0.6084421090733325  MAPE: 1.141361462275251  L2+L1 loss: 0.53
Epoch [57/75], Batch loss: 0.46
Epoch: 57 RMSE:  1.2544820309644458  MAPE: 0.9685918838894833  L2+L1 loss: 0.72
Epoch [58/75], Batch loss: 0.46
Epoch: 58 RMSE:  0.5672616597007246  MAPE: 0.5143883403620042  L2+L1 loss: 0.376
Epoch [59/75], Batch loss: 0.389
Epoch: 59 RMSE:  0.5720886333287237  MAPE: 0.8558998230053656  L2+L1 loss: 0.48
Epoch [60/75], Batch loss: 0.391
Epoch: 60 RMSE:  0.555968623263031  MAPE: 0.38154502598916457  L2+L1 loss: 0.353
Epoch [61/75], Batch loss: 0.376
Epoch: 61 RMSE:  0.552045689348779  MAPE: 0.44880780473445425  L2+L1 loss: 0.356
Epoch [62/75], Batch loss: 0.35
Epoch: 62 RMSE:  0.5424901616119361  MAPE: 0.25921981767881663  L2+L1 loss: 0.277
Epoch [63/75], Batch loss: 0.324
Epoch: 63 RMSE:  0.5392457820386777  MAPE: 0.19853582702531183  L2+L1 loss: 0.254
Epoch [64/75], Batch loss: 0.329
Epoch: 64 RMSE:  0.5391654115899152  MAPE: 0.31115785590732437  L2+L1 loss: 0.308
Epoch [65/75], Batch loss: 0.316
Epoch: 65 RMSE:  0.5346183475464302  MAPE: 0.2161745581402263  L2+L1 loss: 0.259
Epoch [66/75], Batch loss: 0.324
Epoch: 66 RMSE:  0.5327184590538545  MAPE: 0.22626293433853922  L2+L1 loss: 0.265
Epoch [67/75], Batch loss: 0.307
Epoch: 67 RMSE:  0.5320792316240864  MAPE: 0.19459662917517861  L2+L1 loss: 0.265
Epoch [68/75], Batch loss: 0.251
Epoch: 68 RMSE:  0.18799117328941556  MAPE: 0.425355699616706  L2+L1 loss: 0.329
Epoch [69/75], Batch loss: 0.175
Epoch: 69 RMSE:  0.13388940274087055  MAPE: 0.40970812026373404  L2+L1 loss: 0.314
Epoch [70/75], Batch loss: 0.149
Epoch: 70 RMSE:  0.18017010230758618  MAPE: 0.3279495339818174  L2+L1 loss: 0.292
Epoch [71/75], Batch loss: 0.126
Epoch: 71 RMSE:  0.12199542429651943  MAPE: 0.3181093934005381  L2+L1 loss: 0.271
Epoch [72/75], Batch loss: 0.139
Epoch: 72 RMSE:  0.0940467604854113  MAPE: 0.31452605272014983  L2+L1 loss: 0.263
Epoch [73/75], Batch loss: 0.102
Epoch: 73 RMSE:  0.08655644434199282  MAPE: 0.27558252974019865  L2+L1 loss: 0.247
Epoch [74/75], Batch loss: 0.098
Epoch: 74 RMSE:  0.09697861468436635  MAPE: 0.22080360676169514  L2+L1 loss: 0.232


Evaluating Model.......
Best Model - RMSE: inf  MAPE: inf  L2+L1- inf
predicted_runtime, ground_truth
0.6238539 , 0.5573
0.38190338 , 0.4225
0.44783705 , 0.3508
0.057603896 , 0.1482
0.5242173 , 0.4814
0.13065922 , 0.1658
0.36179024 , 0.3601
0.6799304 , 0.8047
0.92474204 , 1.1077
0.10193962 , 0.1583
0.22927576 , 0.2795
0.40630728 , 0.3898
0.7352752 , 0.7466
0.113313675 , 0.1024
0.32443434 , 0.1469
0.11362779 , 0.1482
0.19274431 , 0.2955
0.13608426 , 0.1734
0.07324654 , 0.1554
0.29393065 , 0.4067
0.22037601 , 0.2425
0.12566096 , 0.1011
0.6569467 , 0.5592
0.24199265 , 0.2291
0.13528687 , 0.2357
0.325858 , 0.2571
0.83999366 , 0.9277
0.25279212 , 0.2773
0.40076447 , 0.4619
0.51846224 , 0.6626
0.120408714 , 0.1444
0.26684606 , 0.3482
0.21240711 , 0.4152
0.07489127 , 0.1126
0.6260387 , 0.4678
0.53911424 , 0.49
0.30290413 , 0.4399
0.46968824 , 0.4838
0.32749122 , 0.3771
0.30628496 , 0.2725
0.08302909 , 0.14
0.14402527 , 0.151
0.058272183 , 0.1037
0.58301455 , 0.6056
0.29340672 , 0.2377
0.8374683 , 0.8184
0.121355295 , 0.2279
0.20635515 , 0.174
0.08309388 , 0.1124
0.14937443 , 0.2306
0.11897999 , 0.1098
0.17239416 , 0.1923
0.19657153 , 0.2429
0.17446166 , 0.1316
0.58131593 , 0.5398
0.47465587 , 0.5236
0.44635054 , 0.4815
0.35752222 , 0.3344
0.13003558 , 0.101
0.641035 , 0.758
0.47739917 , 0.5608
6.785224 , 7.3804
0.78709155 , 0.7585
0.27738476 , 0.1451
0.864391 , 0.728
0.37588286 , 0.3808
0.42866075 , 0.4457
0.1496113 , 0.1963
0.4202685 , 0.4522
0.076198995 , 0.1114
1.0324957 , 1.0233
0.26729006 , 0.2834
0.38376462 , 0.5325
0.19089502 , 0.3359
0.382751 , 0.5808
0.1535644 , 0.1513
0.11183268 , 0.1073
0.2397945 , 0.5063
0.18116552 , 0.2959
0.22502643 , 0.3165
0.11776525 , 0.2317
0.56804687 , 0.5871
0.7071013 , 0.6851
0.30916047 , 0.5147
0.71419364 , 0.6621
0.21529323 , 0.4138
0.10587031 , 0.1764
0.8471641 , 1.0211
0.13140696 , 0.1478
0.14805025 , 0.2022
0.5591282 , 0.6306
0.61498815 , 0.6912
0.3711269 , 0.2637
1.2703786 , 1.2467
0.07520586 , 0.1058
0.059312403 , 0.1308
0.68397325 , 0.5765
0.11760932 , 0.1119
0.3053674 , 0.3028
0.11555964 , 0.1338
0.12106562 , 0.1005
0.091298044 , 0.1462
0.11807197 , 0.1095
0.22232002 , 0.2291
0.36669326 , 0.3779
0.19013244 , 0.2777
0.9872572 , 0.9949
0.2347514 , 0.2264
0.17687851 , 0.2823
0.31281745 , 0.2837
0.23520213 , 0.2363
0.059423923 , 0.119
0.092163265 , 0.1306
0.36065227 , 0.4502
0.1208179 , 0.1608
0.89633983 , 0.8393
0.44232088 , 0.4301
0.15310806 , 0.3936
0.24521905 , 0.2499
0.8104686 , 0.7223
0.36389434 , 0.3144
0.07052094 , 0.1356
0.33953726 , 0.1924
0.09664714 , 0.1494
0.6654591 , 0.7561
0.1231913 , 0.1394
0.20600325 , 0.2581
1.0421143 , 0.8737
0.929061 , 0.9511
0.17691332 , 0.1246
0.48289806 , 0.5582
0.48271066 , 0.5313
0.06096983 , 0.1438
0.07714623 , 0.1045
0.60401994 , 0.5679
0.36053607 , 0.3218
0.7541868 , 0.7522
0.12607461 , 0.1097
0.123174965 , 0.1345
0.30216628 , 0.2688
0.29503554 , 0.2293
0.25548857 , 0.2645
0.28489882 , 0.2507
0.056696713 , 0.1427
0.4995528 , 0.3874
0.1423322 , 0.1074
0.5749003 , 0.5043
0.093732834 , 0.1342
0.30641073 , 0.4302
0.37984473 , 0.4209
0.29292655 , 0.2709
6.4115515 , 6.8722
0.7591923 , 0.6801
0.6120806 , 0.5431
0.1125232 , 0.1531
0.409603 , 0.4407
0.33510858 , 0.3338
0.3995964 , 0.6177
0.7754292 , 0.7978
0.27152878 , 0.3584
0.46630365 , 0.4082
0.15774673 , 0.2312
0.3103604 , 0.404
0.12589192 , 0.1188
0.1372881 , 0.1771
0.21514845 , 0.2299
0.10318023 , 0.1817
0.38544858 , 0.3671
0.31409615 , 0.2998
0.11630708 , 0.1073
0.20178795 , 0.1601
0.3296515 , 0.4623
0.32350004 , 0.4264
0.101974905 , 0.3206
0.3259775 , 0.3846
0.28220028 , 0.2719
0.7098451 , 0.7315
0.7458679 , 0.7571
0.21442246 , 0.2398
0.7801886 , 0.6607
0.43085027 , 0.4274
0.30664754 , 0.422
0.10296303 , 0.2446
0.728224 , 0.6503
0.265204 , 0.2797
0.50101763 , 0.4361
0.21419662 , 0.2219
0.55163854 , 0.5559
0.05979997 , 0.1042
0.30140978 , 0.3727
0.5288537 , 0.6899
0.0 , 0.1062
0.1861242 , 0.1191
0.77429307 , 0.8311
0.29247808 , 0.288
0.13962168 , 0.1846
0.22181314 , 0.2293
0.11620551 , 0.1821
0.4381357 , 0.4109
0.7206535 , 0.8617
0.08383864 , 0.111
0.18428594 , 0.3301
0.08951151 , 0.1598
0.15701783 , 0.2034
0.33744246 , 0.4501
0.21937948 , 0.3096
0.55099946 , 0.4682
0.13766932 , 0.1085
0.43782258 , 0.4853
0.13702685 , 0.1013
0.09672624 , 0.1398
0.247854 , 0.3868
0.40548924 , 0.3496
0.7720888 , 0.7966
0.40932572 , 0.4397
0.4246204 , 0.4115
0.42916232 , 0.4014
0.11970824 , 0.2069
0.37786874 , 0.2766
0.12308711 , 0.1404
0.19870293 , 0.3531
0.11715889 , 0.1771
0.41539752 , 0.3879
0.14155823 , 0.1062
0.33234957 , 0.2622
0.32557455 , 0.3218
0.08494431 , 0.1631
0.19924289 , 0.257
0.31044632 , 0.3457
0.12926793 , 0.1408
0.23741949 , 0.2057
0.33011043 , 0.4268
0.28799152 , 0.4007
0.48225868 , 0.3885
0.17902392 , 0.3513
0.6060823 , 0.5177
0.16261977 , 0.1495
0.1460855 , 0.1297
0.23434281 , 0.241
0.33511096 , 0.2977
0.2844482 , 0.2828
0.2809028 , 0.2958
0.2500146 , 0.4471
0.19633818 , 0.1698
0.7384866 , 0.6916
0.10852045 , 0.1183
0.32049507 , 0.39
0.26957893 , 0.1543
0.5206577 , 0.4577
0.057527363 , 0.1184
1.3675032 , 1.3754
0.11617631 , 0.1196
0.3949141 , 0.3796
0.21349156 , 0.2785
0.17018801 , 0.2214
0.7678487 , 0.6534
1.2108207 , 1.0753
0.4933458 , 0.4573
0.11972159 , 0.1932
0.07794851 , 0.1539
0.37335077 , 0.3158
0.21023607 , 0.2648
0.094552934 , 0.1193
0.055302024 , 0.1111
0.35614735 , 0.2658
0.4781863 , 0.43
0.31427407 , 0.3699
0.28486484 , 0.4453
0.23461151 , 0.2884
0.26271862 , 0.27
1.2024233 , 1.2833
0.17738491 , 0.1937
0.22978717 , 0.2316
0.101643264 , 0.2108
0.29404813 , 0.3517
0.30241197 , 0.3697
0.20194203 , 0.172
0.18522483 , 0.3012
5.5992117 , 5.8948
0.5859415 , 0.5112
0.31118464 , 0.2701
0.24382192 , 0.4249
0.08371848 , 0.1499
0.76768607 , 0.9135
0.16134173 , 0.1849
0.59827346 , 0.5899
0.12923235 , 0.1259
0.18355638 , 0.3156
0.6208433 , 0.5848
0.11200136 , 0.149
0.27209324 , 0.208
0.10804671 , 0.1048
RMSE:  0.09264081540545861  MAPE: 0.2115574779082419
5: ground truth total-  289  predicted total -  289
100: ground truth total-  3  predicted total -  3
 more 100: ground truth total -  0  predicted total -  0
