['Outer', 'Inner', 'Reduction', 'VarDecl', 'refExpr', 'intLiteral', 'floatLiteral', 'mem_to', 'mem_from', 'add_sub_int', 'add_sub_double', 'mul_int', 'mul_double', 'div_int', 'div_double', 'assign_int', 'assign_double', 'log_Outer', 'log_Inner', 'log_VarDecl', 'log_refExpr', 'log_intLiteral', 'log_floatLiteral', 'log_mem_to', 'log_mem_from', 'log_add_sub_int', 'log_add_sub_double', 'log_mul_int', 'log_mul_double', 'log_div_int', 'log_div_double', 'log_assign_int', 'log_assign_double', 'runtimes']
2010
34
<class 'numpy.dtype'> float64
2010
train batches:  91  validate samples: 160  test samples: 402
Epoch [0/75], Batch loss: 12.583
Epoch: 0 RMSE:  9.833018490942257  MAPE: 0.8985819748976667  L2+L1 loss: 3.568
Epoch [1/75], Batch loss: 4.771
Epoch: 1 RMSE:  9.60957885700075  MAPE: 1.2052626826417137  L2+L1 loss: 3.25
Epoch [2/75], Batch loss: 4.264
Epoch: 2 RMSE:  9.442908521117175  MAPE: 2.356563131724276  L2+L1 loss: 3.287
Epoch [3/75], Batch loss: 4.407
Epoch: 3 RMSE:  9.367357630557052  MAPE: 3.1743654612453205  L2+L1 loss: 3.375
Epoch [4/75], Batch loss: 6.301
Epoch: 4 RMSE:  9.38060984153199  MAPE: 3.000666656203582  L2+L1 loss: 3.348
Epoch [5/75], Batch loss: 4.417
Epoch: 5 RMSE:  9.336129393096696  MAPE: 3.6885864391433953  L2+L1 loss: 3.476
Epoch [6/75], Batch loss: 4.369
Epoch: 6 RMSE:  9.338272410280247  MAPE: 3.6462417119159753  L2+L1 loss: 3.468
Epoch [7/75], Batch loss: 4.476
Epoch: 7 RMSE:  9.343023339510111  MAPE: 3.557091667563109  L2+L1 loss: 3.447
Epoch [8/75], Batch loss: 4.475
Epoch: 8 RMSE:  9.329486446890275  MAPE: 3.8305617433771473  L2+L1 loss: 3.505
Epoch [9/75], Batch loss: 4.374
Epoch: 9 RMSE:  9.320199353656697  MAPE: 4.070617859329588  L2+L1 loss: 3.562
Epoch [10/75], Batch loss: 4.438
Epoch: 10 RMSE:  9.346632791941051  MAPE: 3.4934774484392888  L2+L1 loss: 3.436
Epoch [11/75], Batch loss: 4.469
Epoch: 11 RMSE:  9.349943372407338  MAPE: 3.4376765475091773  L2+L1 loss: 3.425
Epoch [12/75], Batch loss: 4.441
Epoch: 12 RMSE:  9.312786850720133  MAPE: 4.330940737064493  L2+L1 loss: 3.63
Epoch [13/75], Batch loss: 4.425
Epoch: 13 RMSE:  9.360506113297618  MAPE: 3.2726654193630993  L2+L1 loss: 3.394
Epoch [14/75], Batch loss: 4.476
Epoch: 14 RMSE:  9.31573187979664  MAPE: 4.215826937930481  L2+L1 loss: 3.601
Epoch [15/75], Batch loss: 4.44
Epoch: 15 RMSE:  9.338111499136785  MAPE: 3.6493718495682272  L2+L1 loss: 3.468
Epoch [16/75], Batch loss: 4.477
Epoch: 16 RMSE:  9.332513055462488  MAPE: 3.763587208171829  L2+L1 loss: 3.491
Epoch [17/75], Batch loss: 4.47
Epoch: 17 RMSE:  9.320556360784753  MAPE: 4.060078150837343  L2+L1 loss: 3.559
Epoch [18/75], Batch loss: 7.481
Epoch: 18 RMSE:  9.311231321862069  MAPE: 5.4532543406566045  L2+L1 loss: 3.952
Epoch [19/75], Batch loss: 4.612
Epoch: 19 RMSE:  9.322687421417655  MAPE: 3.999833348201625  L2+L1 loss: 3.545
Epoch [20/75], Batch loss: 4.41
Epoch: 20 RMSE:  9.335508002661093  MAPE: 3.7011420602432095  L2+L1 loss: 3.479
Epoch [21/75], Batch loss: 4.481
Epoch: 21 RMSE:  9.335249787138077  MAPE: 3.7063980091845297  L2+L1 loss: 3.48
Epoch [22/75], Batch loss: 4.459
Epoch: 22 RMSE:  9.334143488721713  MAPE: 3.7291814957304283  L2+L1 loss: 3.485
Epoch [23/75], Batch loss: 4.515
Epoch: 23 RMSE:  9.35637869055045  MAPE: 3.3350231416267677  L2+L1 loss: 3.406
Epoch [24/75], Batch loss: 4.483
Epoch: 24 RMSE:  9.34866305210537  MAPE: 3.458969586180177  L2+L1 loss: 3.429
Epoch [25/75], Batch loss: 4.267
Epoch: 25 RMSE:  9.345191764207549  MAPE: 3.518514574510809  L2+L1 loss: 3.441
Epoch [26/75], Batch loss: 16.659
Epoch: 26 RMSE:  9.335533244485278  MAPE: 3.700629491531379  L2+L1 loss: 3.479
Epoch [27/75], Batch loss: 4.576
Epoch: 27 RMSE:  9.348765551189834  MAPE: 3.457253365889403  L2+L1 loss: 3.429
Epoch [28/75], Batch loss: 5.073
Epoch: 28 RMSE:  9.326182344455171  MAPE: 3.9089736529999444  L2+L1 loss: 3.521
Epoch [29/75], Batch loss: 4.645
Epoch: 29 RMSE:  9.353977414278752  MAPE: 4.934612745151855  L2+L1 loss: 3.877
Epoch [30/75], Batch loss: 4.634
Epoch: 30 RMSE:  9.31488955417162  MAPE: 4.246747656255259  L2+L1 loss: 3.609
Epoch [31/75], Batch loss: 4.532
Epoch: 31 RMSE:  9.326593388229718  MAPE: 3.898880393403168  L2+L1 loss: 3.52
Epoch [32/75], Batch loss: 4.469
Epoch: 32 RMSE:  9.325283514195972  MAPE: 3.931503167994909  L2+L1 loss: 3.527
Epoch [33/75], Batch loss: 4.373
Epoch: 33 RMSE:  9.332912056791624  MAPE: 3.755070840358018  L2+L1 loss: 3.489
Epoch [34/75], Batch loss: 4.504
Epoch: 34 RMSE:  9.334174727935837  MAPE: 3.72853211356544  L2+L1 loss: 3.484
Epoch [35/75], Batch loss: 4.476
Epoch: 35 RMSE:  9.333429584061788  MAPE: 3.7441203686452544  L2+L1 loss: 3.487
Epoch [36/75], Batch loss: 4.477
Epoch: 36 RMSE:  9.330268554615403  MAPE: 3.8128634643298414  L2+L1 loss: 3.502
Epoch [37/75], Batch loss: 4.571
Epoch: 37 RMSE:  9.341417698308247  MAPE: 3.586542100419419  L2+L1 loss: 3.454
Epoch [38/75], Batch loss: 4.535
Epoch: 38 RMSE:  9.359823703668361  MAPE: 4.089564206086854  L2+L1 loss: 3.679
Epoch [39/75], Batch loss: 4.474
Epoch: 39 RMSE:  9.206565417971417  MAPE: 1.507766511234725  L2+L1 loss: 2.72
Epoch [40/75], Batch loss: 3.549
Epoch: 40 RMSE:  8.86035026780503  MAPE: 0.4991503537447814  L2+L1 loss: 2.157
Epoch [41/75], Batch loss: 3.232
Epoch: 41 RMSE:  8.703167277459615  MAPE: 0.5057103030150456  L2+L1 loss: 2.277
Epoch [42/75], Batch loss: 3.357
Epoch: 42 RMSE:  8.493032563404485  MAPE: 0.5264478090271878  L2+L1 loss: 2.015
Epoch [43/75], Batch loss: 3.128
Epoch: 43 RMSE:  9.687167889311326  MAPE: 4.465913670836638  L2+L1 loss: 3.88
Epoch [44/75], Batch loss: 3.699
Epoch: 44 RMSE:  2.935802704097919  MAPE: 0.33984707397368824  L2+L1 loss: 1.751
Epoch [45/75], Batch loss: 3.307
Epoch: 45 RMSE:  9.341477613820635  MAPE: 3.4460022939731916  L2+L1 loss: 3.414
Epoch [46/75], Batch loss: 3.939
Epoch: 46 RMSE:  5.763803579573685  MAPE: 1.0753766861214884  L2+L1 loss: 2.025
Epoch [47/75], Batch loss: 5.149
Epoch: 47 RMSE:  9.209890007645713  MAPE: 1.8408849020112676  L2+L1 loss: 2.951
Epoch [48/75], Batch loss: 3.773
Epoch: 48 RMSE:  9.104693287085862  MAPE: 0.596009663971061  L2+L1 loss: 2.304
Epoch [49/75], Batch loss: 3.503
Epoch: 49 RMSE:  9.05030273796938  MAPE: 0.4435655364991261  L2+L1 loss: 2.123
Epoch [50/75], Batch loss: 3.546
Epoch: 50 RMSE:  8.997490772440813  MAPE: 0.34975563982523633  L2+L1 loss: 2.059
Epoch [51/75], Batch loss: 3.318
Epoch: 51 RMSE:  8.93784910797415  MAPE: 0.2349710540135026  L2+L1 loss: 1.877
Epoch [52/75], Batch loss: 3.362
Epoch: 52 RMSE:  3.7795787656369066  MAPE: 1.9425513215514694  L2+L1 loss: 2.972
Epoch [53/75], Batch loss: 2.809
Epoch: 53 RMSE:  7.813399566787118  MAPE: 0.5219980029950501  L2+L1 loss: 1.773
Epoch [54/75], Batch loss: 4.162
Epoch: 54 RMSE:  8.994059279483768  MAPE: 0.43501687729851907  L2+L1 loss: 1.782
Epoch [55/75], Batch loss: 2.109
Epoch: 55 RMSE:  0.4122818539985433  MAPE: 0.4263284150423422  L2+L1 loss: 0.623
Epoch [56/75], Batch loss: 1.069
Epoch: 56 RMSE:  3.0408361996152258  MAPE: 0.24899965223253373  L2+L1 loss: 0.878
Epoch [57/75], Batch loss: 0.751
Epoch: 57 RMSE:  0.3790221553713388  MAPE: 0.2138687578694764  L2+L1 loss: 0.459
Epoch [58/75], Batch loss: 0.423
Epoch: 58 RMSE:  0.3892667551731105  MAPE: 0.1647885489593392  L2+L1 loss: 0.411
Epoch [59/75], Batch loss: 0.354
Epoch: 59 RMSE:  7.259887823390172  MAPE: 0.2629990523617246  L2+L1 loss: 1.27
Epoch [60/75], Batch loss: 1.122
Epoch: 60 RMSE:  0.4654251332311519  MAPE: 0.12725822692509497  L2+L1 loss: 0.425
Epoch [61/75], Batch loss: 0.243
Epoch: 61 RMSE:  0.41613836958131084  MAPE: 0.11587926269452517  L2+L1 loss: 0.368
Epoch [62/75], Batch loss: 0.209
Epoch: 62 RMSE:  0.34706158276457666  MAPE: 0.11970997133666557  L2+L1 loss: 0.355
Epoch [63/75], Batch loss: 0.215
Epoch: 63 RMSE:  0.35628218791197813  MAPE: 0.1376063459784424  L2+L1 loss: 0.363
Epoch [64/75], Batch loss: 0.215
Epoch: 64 RMSE:  0.3797359326550908  MAPE: 0.10619402447648071  L2+L1 loss: 0.338
Epoch [65/75], Batch loss: 0.194
Epoch: 65 RMSE:  0.34632005511412506  MAPE: 0.10762203363197434  L2+L1 loss: 0.342
Epoch [66/75], Batch loss: 0.171
Epoch: 66 RMSE:  0.19412315310003372  MAPE: 0.10331112328604315  L2+L1 loss: 0.32
Epoch [67/75], Batch loss: 0.269
Epoch: 67 RMSE:  0.23171419405460156  MAPE: 0.19178674158883702  L2+L1 loss: 0.403
Epoch [68/75], Batch loss: 0.144
Epoch: 68 RMSE:  0.19461695084478584  MAPE: 0.21468667235662492  L2+L1 loss: 0.372
Epoch [69/75], Batch loss: 0.166
Epoch: 69 RMSE:  0.7791523191138606  MAPE: 0.10894698003943912  L2+L1 loss: 0.372
Epoch [70/75], Batch loss: 0.248
Epoch: 70 RMSE:  0.15861509385935676  MAPE: 0.11218766023586939  L2+L1 loss: 0.291
Epoch [71/75], Batch loss: 0.136
Epoch: 71 RMSE:  0.24585643426044101  MAPE: 0.09641916676887323  L2+L1 loss: 0.301
Epoch [72/75], Batch loss: 0.221
Epoch: 72 RMSE:  0.3234759179359791  MAPE: 0.15049298849898274  L2+L1 loss: 0.402
Epoch [73/75], Batch loss: 0.135
Epoch: 73 RMSE:  0.15766022309906194  MAPE: 0.11071868044055475  L2+L1 loss: 0.31
Epoch [74/75], Batch loss: 0.131
Epoch: 74 RMSE:  0.13445293970140992  MAPE: 0.13525883591667706  L2+L1 loss: 0.295


Evaluating Model.......
Best Model - RMSE: inf  MAPE: inf  L2+L1- inf
predicted_runtime, ground_truth
0.38179946 , 0.3009
0.3119185 , 0.2388
0.32450867 , 0.2117
0.41468072 , 0.3727
3.2970076 , 3.3398
4.639628 , 4.6621
5.001928 , 4.8992
2.6329808 , 2.5484
1.7657394 , 1.6528
3.5930882 , 3.0811
0.7336335 , 0.597
0.37627172 , 0.3909
3.177418 , 2.9186
1.5700097 , 1.5185
3.4881487 , 3.5064
2.6267595 , 2.7057
2.7164245 , 2.8776
0.39738202 , 0.3085
8.726325 , 9.2518
3.1276345 , 3.2211
3.4363365 , 3.434
0.23934126 , 0.1281
0.2774999 , 0.2045
1.8390684 , 1.7199
1.2080412 , 1.1275
0.25831962 , 0.1901
0.3835411 , 0.3285
3.3369336 , 3.1856
0.5457175 , 0.5195
0.5388212 , 0.5912
0.33883953 , 0.2597
2.5052228 , 2.4855
6.3727703 , 6.371
0.29842234 , 0.1885
2.2299209 , 2.1892
11.174282 , 11.3981
1.1028619 , 1.0983
0.36825943 , 0.2848
0.27161813 , 0.2001
3.9636722 , 4.2037
0.42386985 , 0.3299
0.5051861 , 0.5013
0.42259502 , 0.332
1.0013845 , 0.9562
1.7642741 , 1.7279
0.30008745 , 0.2603
0.28142262 , 0.2201
0.4323194 , 0.4085
5.3124104 , 5.3665
4.4082437 , 4.8141
0.27850676 , 0.1926
2.0885167 , 2.0425
2.974811 , 2.9654
0.395828 , 0.3754
2.0716147 , 1.9143
1.9981294 , 1.8135
0.4075551 , 0.2995
1.8216548 , 1.8835
1.568089 , 1.6464
1.2383275 , 1.3245
0.46339417 , 0.5829
0.37504864 , 0.4107
0.43675327 , 0.5164
2.2274237 , 2.2117
2.8363311 , 2.8124
0.86755013 , 0.6962
0.46461654 , 0.4601
4.5924144 , 4.5695
0.4279282 , 0.4084
5.5372562 , 5.4861
0.7396531 , 0.7195
1.3826556 , 1.3467
3.6461868 , 3.6812
2.2115617 , 2.0958
2.071561 , 1.8082
0.26262164 , 0.2392
0.33733678 , 0.255
71.81794 , 71.7992
1.127548 , 0.963
3.2254355 , 2.7298
1.1074438 , 1.1553
1.2576573 , 1.1752
0.37815475 , 0.4653
0.31023765 , 0.2144
1.4671466 , 1.5263
1.273952 , 1.3653
0.8294511 , 0.6721
1.8766892 , 1.646
0.4372654 , 0.6048
4.0629973 , 4.313
0.2949648 , 0.2516
0.38794947 , 0.3717
2.5716932 , 2.5029
1.5414734 , 1.5975
5.4687996 , 5.2293
1.5737948 , 1.6438
0.5055976 , 0.567
1.4492421 , 1.5216
0.12437534 , 0.1224
1.254097 , 1.2915
0.27072024 , 0.1511
2.6053877 , 2.5386
0.24951005 , 0.1568
5.3589697 , 5.4244
0.44168282 , 0.4433
1.5993338 , 1.6643
0.46292734 , 0.4936
0.4699731 , 0.5324
3.460156 , 3.5122
2.3144746 , 2.3569
0.32390547 , 0.3157
1.6129749 , 1.3116
3.1117678 , 2.9125
1.6682813 , 1.663
1.3001723 , 1.2967
0.3305602 , 0.3376
2.7706494 , 2.7324
0.30255818 , 0.2304
0.27220392 , 0.2054
8.23758 , 8.1164
0.34571362 , 0.338
3.1426997 , 2.7125
4.5729136 , 4.8009
2.234209 , 2.3706
6.067953 , 5.9891
0.35601735 , 0.2664
0.8883741 , 0.8283
0.29339838 , 0.2542
0.3420074 , 0.2802
1.8060184 , 1.8307
4.2301936 , 4.3137
5.120506 , 5.2075
0.41588378 , 0.3511
0.30737782 , 0.2636
0.38542533 , 0.2963
0.2715478 , 0.209
7.266525 , 7.3643
5.4617934 , 5.4511
7.821013 , 8.0823
2.5150476 , 2.433
4.2102466 , 4.3531
4.1855907 , 4.2799
3.740582 , 3.6143
4.950618 , 4.9015
1.0269728 , 0.6794
5.195979 , 5.0752
0.36143565 , 0.2861
1.3454719 , 1.2119
2.9375334 , 2.7573
6.2480135 , 6.1561
0.37628722 , 0.2678
4.8643303 , 4.8722
2.519789 , 2.5706
0.38854218 , 0.3629
0.4165423 , 0.4367
0.30003572 , 0.24
0.50583243 , 0.5008
94.60255 , 94.6865
1.9586668 , 2.1359
0.2862301 , 0.2384
0.49629402 , 0.5838
5.600025 , 5.5134
3.2365115 , 3.07
0.3517561 , 0.4041
0.3792734 , 0.4404
0.30752635 , 0.2692
4.0669107 , 4.197
2.0732574 , 2.1737
0.41638088 , 0.4011
0.64129233 , 0.732
0.30755806 , 0.2009
0.38447165 , 0.2996
1.5701671 , 1.539
1.5196617 , 1.3127
3.462275 , 3.2892
0.38418055 , 0.4802
2.165563 , 2.2376
4.1638403 , 4.1412
10.067889 , 10.2134
1.1709888 , 1.077
1.4300587 , 1.3052
0.27543855 , 0.1414
0.56202006 , 0.6373
4.7305636 , 4.7083
0.39681554 , 0.3231
4.196132 , 4.3177
1.532722 , 1.6347
3.6857443 , 3.4667
2.0212588 , 1.6995
0.31545258 , 0.1986
2.8801079 , 2.9466
3.2184172 , 3.5454
0.42582083 , 0.3423
7.47634 , 7.5136
0.49259496 , 0.3938
1.5880585 , 1.4837
2.15061 , 2.3176
0.2815256 , 0.208
0.33562112 , 0.2639
4.0475216 , 3.85
1.7785842 , 1.7856
2.569734 , 2.5913
3.8613343 , 3.9363
0.4003806 , 0.3684
0.3018005 , 0.2736
0.30730486 , 0.2872
0.3029976 , 0.2625
0.3778417 , 0.4323
2.4732556 , 2.4566
3.1509748 , 3.1111
0.0 , 0.3577
0.36457968 , 0.2836
5.12979 , 5.4476
0.38539934 , 0.3142
0.38467813 , 0.3943
0.30688882 , 0.2099
0.30430794 , 0.3721
2.6679463 , 2.5854
0.2691412 , 0.1533
2.5897477 , 2.39
2.5188901 , 2.7574
5.3109527 , 5.2287
0.47629547 , 0.5241
7.4449115 , 7.6387
4.0108037 , 4.016
0.2717762 , 0.2167
3.7293334 , 3.899
0.2556007 , 0.1405
0.31609988 , 0.199
0.27316666 , 0.1937
0.35307765 , 0.3277
0.2831645 , 0.2442
0.5369661 , 0.4851
0.6648209 , 0.6952
0.52220154 , 0.4635
5.507315 , 5.9119
0.3059728 , 0.2385
1.3520925 , 1.2593
4.480452 , 4.5542
7.0451384 , 6.8883
0.68612266 , 0.7144
0.48953772 , 0.5278
0.5441513 , 0.4955
0.4032557 , 0.3268
2.190201 , 2.291
1.7846496 , 1.6967
10.065754 , 10.1142
2.3275635 , 2.3753
0.6435294 , 0.516
0.40009975 , 0.3664
0.37472916 , 0.2982
0.36991143 , 0.399
7.975678 , 7.7666
5.1841116 , 5.1518
0.3531809 , 0.2605
0.35557127 , 0.2963
0.30549145 , 0.2262
0.95720744 , 0.9297
0.4385023 , 0.4053
2.0820928 , 2.1628
0.5150666 , 0.4947
0.3283913 , 0.227
4.17012 , 4.1092
2.8778095 , 2.9506
0.2569635 , 0.2152
0.44512343 , 0.4543
2.2127957 , 2.2578
1.3787458 , 1.137
5.284477 , 5.2964
0.32377982 , 0.3152
2.18807 , 2.3202
0.7483549 , 0.7863
0.74717116 , 0.8122
0.35588717 , 0.2563
0.2676556 , 0.2247
0.5385356 , 0.6242
0.40983725 , 0.4788
0.26577377 , 0.5439
2.4663692 , 2.438
0.3190217 , 0.3163
3.3440032 , 3.4657
0.3772092 , 0.3497
0.40489316 , 0.4135
0.81909037 , 0.7605
0.37575483 , 0.4142
0.9844475 , 1.267
5.0762935 , 5.1214
3.1512284 , 2.6932
0.48323178 , 0.2774
1.0122595 , 0.8396
0.30197453 , 0.2124
1.3205647 , 1.2064
0.35422325 , 0.3152
0.4416387 , 0.3739
0.41009784 , 0.3381
0.25914717 , 0.138
0.49331307 , 0.369
0.27339768 , 0.1701
0.67740536 , 0.6406
0.29292083 , 0.2204
2.1697755 , 2.1308
1.3213775 , 1.4284
0.32118654 , 0.2225
0.68406963 , 0.7093
9.591003 , 9.7493
0.56181264 , 0.522
3.518211 , 3.4657
1.6029899 , 1.4524
4.4512706 , 4.6482
0.43527842 , 0.4481
3.8347049 , 3.6714
0.2950058 , 0.2508
1.8326678 , 1.9276
4.943205 , 4.9426
0.28960586 , 0.2374
2.0211227 , 1.9941
4.12944 , 3.9372
0.3625369 , 0.3291
5.948349 , 6.2085
0.52416134 , 0.4172
0.35898685 , 0.2904
5.6757693 , 5.8664
0.39635897 , 0.3302
1.6975644 , 1.63
0.3762591 , 0.2966
1.8067946 , 1.7741
0.305156 , 0.2036
0.38007617 , 0.4159
1.0881791 , 0.8849
7.1881523 , 7.3018
0.44769812 , 0.4249
0.36167812 , 0.4745
0.31929946 , 0.2344
4.448005 , 4.5141
1.0090206 , 0.9557
0.86505747 , 0.848
0.43608165 , 0.3439
4.948265 , 4.9671
0.8025565 , 0.757
0.40263224 , 0.4173
0.41411638 , 0.4754
0.6002252 , 0.5347
0.40301347 , 0.3329
0.46827483 , 0.44
2.2698417 , 2.3782
7.933616 , 7.6002
1.4293237 , 1.3833
0.322783 , 0.267
0.38530564 , 0.3202
3.3267884 , 3.336
0.3826661 , 0.2758
0.271801 , 0.1609
1.3470483 , 1.3522
1.517957 , 1.6719
10.133794 , 10.1014
0.7686477 , 0.8859
0.40989566 , 0.3983
1.5666134 , 1.7204
2.5110114 , 2.3591
1.5947046 , 1.4614
0.35809374 , 0.3611
4.410001 , 4.2906
2.5358543 , 2.4086
0.35140252 , 0.332
0.97773147 , 0.8998
3.2449527 , 3.2899
0.45106292 , 0.4205
4.4167094 , 4.5894
3.31741 , 3.2022
0.47294736 , 0.4873
0.8036237 , 0.7758
4.8135147 , 4.9914
0.29900002 , 0.2955
0.3395183 , 0.3168
3.2812314 , 3.1536
0.436306 , 0.4491
0.24075174 , 0.2006
3.3362863 , 3.1359
3.2570887 , 3.2031
0.33130574 , 0.3132
3.5638413 , 3.5396
0.42382336 , 0.3816
0.41986132 , 0.38
0.5277946 , 0.569
8.787573 , 8.6038
0.29045534 , 0.2131
7.855416 , 7.7233
0.87596416 , 0.7716
1.263777 , 1.4817
0.40520597 , 0.3459
4.8735476 , 4.947
4.102839 , 3.4535
2.058132 , 1.9265
11.91409 , 12.3065
0.48324442 , 0.4426
2.7499323 , 2.6655
0.62279797 , 0.5653
0.38369703 , 0.3339
2.9219441 , 2.9796
0.38087273 , 0.4016
0.38018703 , 0.392
0.49775434 , 0.4671
RMSE:  0.1288646209566818  MAPE: 0.13065941716676846
5: ground truth total-  363  predicted total -  363
100: ground truth total-  39  predicted total -  39
 more 100: ground truth total -  0  predicted total -  0
